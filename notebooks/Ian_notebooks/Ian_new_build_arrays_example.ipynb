{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlchartist.preprocessing import fit_train_scaler, train_test_split, train_test_split_multiple_companies\n",
    "from mlchartist.array_builder import full_dataset_randomised_arrays\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df 19103\n",
      "\n",
      "trains 17603\n",
      "tests 1500\n"
     ]
    }
   ],
   "source": [
    "apple = pd.read_csv('../../raw_data/processed/aapl.csv')\n",
    "google = pd.read_csv('../../raw_data/processed/googl.csv')\n",
    "amzn = pd.read_csv('../../raw_data/processed/amzn.csv')\n",
    "\n",
    "joined_df = pd.DataFrame()\n",
    "joined_df = joined_df.append(apple)\n",
    "joined_df = joined_df.append(google)\n",
    "joined_df = joined_df.append(amzn)\n",
    "\n",
    "print('joined_df', len(joined_df))\n",
    "print('')\n",
    "\n",
    "\n",
    "apple_train, apple_test = train_test_split(apple, 500)\n",
    "google_train, google_test = train_test_split(google, 500)\n",
    "amazon_train, amazon_test = train_test_split(amzn, 500)\n",
    "\n",
    "print('trains', len(apple_train) + len(google_train) + len(amazon_train))\n",
    "print('tests', len(apple_test) + len(google_test) + len(amazon_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set 17603\n",
      "test_set 1500\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split_multiple_companies(joined_df, 500)\n",
    "\n",
    "print('train_set', len(train_set))\n",
    "print('test_set', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Scaler Function\n",
    "Fits scaler on dataframe after the outliers have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "input_cols=['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', \n",
    "            'ADX_neg', 'MACD', 'MACD_diff', 'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "\n",
    "fitted_scaler = fit_train_scaler(train_set, outlier_validation=outlier_validation, input_cols=input_cols)\n",
    "fitted_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Build Arrays Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Functionality\n",
    "Input full dataframe where the function then splits the data and fits a scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split: Splitting unsplit dataframe\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot do positional indexing on Int64Index with these indexers [3Y] of type str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-348688a2d25f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                                                             \u001b[0mtarget_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTARGET_COLS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                                                                             \u001b[0mtime_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                                                                             test_set_size='3Y')\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\mlchartist\\array_builder.py\u001b[0m in \u001b[0;36mfull_dataset_randomised_arrays\u001b[1;34m(unsplit_df, train_df, test_df, split_dataframe, test_set_size, time_window, stride, verbose, fitted_scaler, check_train_outliers, check_test_outliers, outlier_threshold, input_cols, target_col, outlier_validation)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msplit_dataframe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train/Test Split: Splitting unsplit dataframe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split_multiple_companies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munsplit_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train/Test Split: Not splitting dataframe. (Holdout Data)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\mlchartist\\preprocessing.py\u001b[0m in \u001b[0;36mtrain_test_split_multiple_companies\u001b[1;34m(df, test_set_size)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mcompany_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mtemp_train_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_test_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompany_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_train_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_test_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\mlchartist\\preprocessing.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(input_df, test_set_size)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_set_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_set_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1508\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_positional_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1509\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_validate_positional_slice\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3113\u001b[0m         \"\"\"\n\u001b[0;32m   3114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3115\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_validate_indexer\u001b[1;34m(self, form, key, kind)\u001b[0m\n\u001b[0;32m   4989\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4990\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4991\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4993\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_cast_slice_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[1;34m(self, form, key)\u001b[0m\n\u001b[0;32m   3260\u001b[0m         \"\"\"\n\u001b[0;32m   3261\u001b[0m         raise TypeError(\n\u001b[1;32m-> 3262\u001b[1;33m             \u001b[1;34mf\"cannot do {form} indexing on {type(self).__name__} with these \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3263\u001b[0m             \u001b[1;34mf\"indexers [{key}] of type {type(key).__name__}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3264\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot do positional indexing on Int64Index with these indexers [3Y] of type str"
     ]
    }
   ],
   "source": [
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "              'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "TARGET_COLS=['5TD_return', '10TD_return', '20TD_return']\n",
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "\n",
    "stride = 100\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y, scaler = full_dataset_randomised_arrays(unsplit_df=joined_df, \n",
    "                                                                          #IMPORTANT: need use unsplit_df=df\n",
    "                                                                            #train_df=train_set, \n",
    "                                                                            #test_df=test_set, \n",
    "                                                                            stride=stride,\n",
    "                                                                            #fitted_scaler=scaler,\n",
    "                                                                            #split_dataframe=True,\n",
    "                                                                            input_cols=INPUT_COLS, \n",
    "                                                                            outlier_threshold=1, \n",
    "                                                                            outlier_validation=outlier_validation, \n",
    "                                                                            check_train_outliers=True,\n",
    "                                                                            check_test_outliers=True, \n",
    "                                                                            target_col=TARGET_COLS, \n",
    "                                                                            time_window=6,\n",
    "                                                                            test_set_size='3Y')\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('train_x', train_x.shape)\n",
    "print('train_y', train_y.shape)\n",
    "print('test_x', test_x.shape)\n",
    "print('test_y', test_y.shape)\n",
    "print('scaler', scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass Fitted Scaler to Function\n",
    "Input full dataframe with a pre-fitted scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split: Splitting unsplit dataframe\n",
      "Scaler: Using provided fitted_scaler\n",
      "3 Companies in Dataset\n",
      "Starting AAPL: Company 1 of 3\n",
      "Starting GOOGL: Company 2 of 3\n",
      "Starting AMZN: Company 3 of 3\n",
      "All Companies Completed\n",
      "\n",
      "\n",
      "\n",
      "### Stats ###\n",
      "train_x (170, 6, 15)\n",
      "train_y (170, 3)\n",
      "test_x (24, 6, 15)\n",
      "test_y (24, 3)\n",
      "scaler RobustScaler()\n"
     ]
    }
   ],
   "source": [
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "              'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "TARGET_COLS=['5TD_return', '10TD_return', '20TD_return']\n",
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "\n",
    "stride = 100\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y, scaler = full_dataset_randomised_arrays(unsplit_df=joined_df, \n",
    "                                                                          #IMPORTANT: need use unsplit_df=df\n",
    "                                                                            stride=stride,\n",
    "                                                                            fitted_scaler=fitted_scaler, ## <-- HERE\n",
    "                                                                            input_cols=INPUT_COLS, \n",
    "                                                                            outlier_threshold=1, \n",
    "                                                                            outlier_validation=outlier_validation, \n",
    "                                                                            check_train_outliers=True,\n",
    "                                                                            check_test_outliers=True, \n",
    "                                                                            target_col=TARGET_COLS, \n",
    "                                                                            time_window=6,\n",
    "                                                                            test_set_size='3Y')\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('train_x', train_x.shape)\n",
    "print('train_y', train_y.shape)\n",
    "print('test_x', test_x.shape)\n",
    "print('test_y', test_y.shape)\n",
    "print('scaler', scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass Pre Split Train & Test Set\n",
    "Instead of inputting a full dataframe, input a train and test set into the function. <br>\n",
    "NOTE: By default the function will use the unsplit_df so make sure unsplit_df=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split: Using provided train/test split dataframe\n",
      "Scaler: Fitting scaler on train set\n",
      "3 Companies in Dataset\n",
      "Starting AAPL: Company 1 of 3\n",
      "Starting GOOGL: Company 2 of 3\n",
      "Starting AMZN: Company 3 of 3\n",
      "All Companies Completed\n",
      "\n",
      "\n",
      "\n",
      "### Stats ###\n",
      "train_x (170, 6, 15)\n",
      "train_y (170, 3)\n",
      "test_x (24, 6, 15)\n",
      "test_y (24, 3)\n",
      "scaler RobustScaler()\n"
     ]
    }
   ],
   "source": [
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "              'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "TARGET_COLS=['5TD_return', '10TD_return', '20TD_return']\n",
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "\n",
    "stride = 100\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y, scaler = full_dataset_randomised_arrays(unsplit_df=None, \n",
    "                                                                            train_df=train_set,  ## <-- HERE\n",
    "                                                                            test_df=test_set,     ## <-- HERE\n",
    "                                                                            stride=stride,\n",
    "                                                                            input_cols=INPUT_COLS, \n",
    "                                                                            outlier_threshold=1, \n",
    "                                                                            outlier_validation=outlier_validation, \n",
    "                                                                            check_train_outliers=True,\n",
    "                                                                            check_test_outliers=True, \n",
    "                                                                            target_col=TARGET_COLS, \n",
    "                                                                            time_window=6,\n",
    "                                                                            test_set_size='3Y')\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('train_x', train_x.shape)\n",
    "print('train_y', train_y.shape)\n",
    "print('test_x', test_x.shape)\n",
    "print('test_y', test_y.shape)\n",
    "print('scaler', scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't Split The Data (Holdout Dataset)\n",
    "Uses the unsplit_df dataframe but doesn't split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split: Not splitting dataframe. (Holdout Data)\n",
      "Scaler: Fitting scaler on train set\n",
      "3 Companies in Dataset\n",
      "Starting AAPL: Company 1 of 3\n",
      "Starting GOOGL: Company 2 of 3\n",
      "Starting AMZN: Company 3 of 3\n",
      "All Companies Completed\n",
      "\n",
      "\n",
      "\n",
      "### Stats ###\n",
      "holdout_x (192, 6, 15)\n",
      "holdout_y (192, 3)\n",
      "scaler RobustScaler()\n"
     ]
    }
   ],
   "source": [
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "              'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "TARGET_COLS=['5TD_return', '10TD_return', '20TD_return']\n",
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "\n",
    "stride = 100\n",
    "\n",
    "\n",
    "holdout_x, holdout_y, scaler = full_dataset_randomised_arrays(unsplit_df=joined_df, \n",
    "                                                                            stride=stride,\n",
    "                                                                            split_dataframe=False, ## <-- HERE, use for holdout\n",
    "                                                                            input_cols=INPUT_COLS, \n",
    "                                                                            outlier_threshold=1, \n",
    "                                                                            outlier_validation=outlier_validation, \n",
    "                                                                            check_train_outliers=True,\n",
    "                                                                            check_test_outliers=True, \n",
    "                                                                            target_col=TARGET_COLS, \n",
    "                                                                            time_window=6,\n",
    "                                                                            test_set_size='3Y')\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('holdout_x', holdout_x.shape)\n",
    "print('holdout_y', holdout_y.shape)\n",
    "print('scaler', scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
