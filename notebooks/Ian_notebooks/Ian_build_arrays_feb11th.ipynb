{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlchartist.preprocessing import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df 19103\n",
      "\n",
      "trains 16850\n",
      "tests 2253\n"
     ]
    }
   ],
   "source": [
    "apple = pd.read_csv('../../raw_data/processed/aapl.csv')\n",
    "google = pd.read_csv('../../raw_data/processed/googl.csv')\n",
    "amzn = pd.read_csv('../../raw_data/processed/amzn.csv')\n",
    "\n",
    "joined_df = pd.DataFrame()\n",
    "joined_df = joined_df.append(apple)\n",
    "joined_df = joined_df.append(google)\n",
    "joined_df = joined_df.append(amzn)\n",
    "\n",
    "print('joined_df', len(joined_df))\n",
    "print('')\n",
    "\n",
    "\n",
    "apple_train, apple_test = train_test_split(apple, '3Y')\n",
    "google_train, google_test = train_test_split(google, '3Y')\n",
    "amazon_train, amazon_test = train_test_split(amzn, '3Y')\n",
    "\n",
    "print('trains', len(apple_train) + len(google_train) + len(amazon_train))\n",
    "print('tests', len(apple_test) + len(google_test) + len(amazon_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "pass scaler --> use a scaler\n",
    "scaler=None\n",
    "\n",
    "#2\n",
    "get_full_ds_scaler + train/test\n",
    "- full 100 NASDAQ\n",
    "- holdout 10 companies --> holdount=[]\n",
    "\n",
    "split function(split=False)\n",
    "- input X companies\n",
    "- X companies -> train/test sets\n",
    "- remove outliers on train\n",
    "- fit scaler on train\n",
    "output - scaler, train, test\n",
    "\n",
    "\n",
    "\n",
    "fit_train_scaler\n",
    "- input train\n",
    "- remove outliers\n",
    "- fit scaler\n",
    "- output scaler\n",
    "\n",
    "\n",
    "90 compainies --> 15 companies X 6 models\n",
    "\n",
    "build_arrays_new\n",
    "- inputs -> full dataframe (without holdout), take in train/test/scaler\n",
    "\n",
    "- split the data -> train/test\n",
    "- if scaler not provided then call fit_train_scaler\n",
    "- scale the train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_multiple_companies(df, test_set_size):\n",
    "    \"\"\"\n",
    "    Split the preprocessed stock data of multiple companies into a train and test dataset\n",
    "    INPUT: the dataframe to be split, and size of the test set in months or years ('3M' or '2Y')\n",
    "    OUTPUT: returns a train_set and test_set dataframe, index is set to the date\n",
    "\n",
    "    EXAMPLE: train_set, test_set = train_test_split_multiple_companies(input_df, '3Y')  --> puts last 3 years in test_set\n",
    "    \"\"\"\n",
    "    train_set = pd.DataFrame()\n",
    "    test_set = pd.DataFrame()\n",
    "    for ticker in df['ticker'].unique():\n",
    "        company_df = df[df['ticker'] == ticker]\n",
    "        temp_train_set, temp_test_set = train_test_split(company_df, test_set_size)\n",
    "        train_set = train_set.append(temp_train_set)\n",
    "        test_set = test_set.append(temp_test_set)\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\mlchartist\\preprocessing.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.to_datetime(df['date'], format=('%Y-%m-%d'))\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split_multiple_companies(joined_df, '3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16850"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2253"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "def fit_train_scaler(train_df, \n",
    "                    outlier_validation={'5TD_return': [-0.5, 0.5]},\n",
    "                    input_cols=['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', \n",
    "                                    'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff', 'MACD_signal', '5TD_return', \n",
    "                                    '10TD_return', '20TD_return']):\n",
    "    \"\"\"\n",
    "    Fits Robust Scaler on train set and returns the scaler\n",
    "    INPUT: the dataframe to used to fit scaler, the outlier_validation thresholds, the columns for the scaler to be\n",
    "            applied too.\n",
    "    OUTPUT: fitted scaler\n",
    "    \"\"\"\n",
    "    no_outlier_train_df = train_df.copy()\n",
    "    for k, v in outlier_validation.items(): \n",
    "        no_outlier_train_df = no_outlier_train_df[no_outlier_train_df[k].between(v[0], v[1])]\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(no_outlier_train_df[input_cols])\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_scaler = fit_train_scaler(train_set)\n",
    "fitted_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated Build Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "a = None\n",
    "if a == None:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def full_dataset_randomised_arrays_NEW(unsplit_df=None,\n",
    "                                       train_df=None,\n",
    "                                       test_df=None,\n",
    "                                       split_dataframe=True,\n",
    "                                         test_set_size='3Y', \n",
    "                                         time_window=5, \n",
    "                                         stride=3, \n",
    "                                         fitted_scaler=None,\n",
    "                                         check_train_outliers=False, \n",
    "                                         check_test_outliers=False, \n",
    "                                         outlier_threshold=1, \n",
    "                                         input_cols=['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', \n",
    "                                                     'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff', 'MACD_signal', '5TD_return', \n",
    "                                                     '10TD_return', '20TD_return'], \n",
    "                                         target_col=['5TD_return', '10TD_return', '20TD_return'], \n",
    "                                         outlier_validation={'ATR': [-100, 100], 'Stochastic': [0, 100], \n",
    "                                                             'Stochastic_signal': [-10, 110], '5TD_return': [-0.5, 0.5]}):\n",
    "    \"\"\"\n",
    "    A function to transform dataframe into input and output arrays.\n",
    "\n",
    "    Takes:\n",
    "    unsplit_df - unsplit dataframe that will be split into test/train\n",
    "    train_df - pre-split training dataframe\n",
    "    test_df - pre-split test dataframe\n",
    "    split_dataframe - boolean to tell the function to split the unsplit dataframe into test/train or not. \n",
    "        Use with holdout data.\n",
    "    fitted_scaler - give the function a prefitted scaler that it will use on the data.\n",
    "    time_window (default=5) - time series length\n",
    "    stride (default=3) - controls the number of windows taken (i.e. max_num_windows = len(df)/strides)\n",
    "    check_outliers (default=False) - controls whether it checks each window for outliers or not\n",
    "    input_cols (default = 'RSI', 'Stochastic', 'Stochastic_signal', 'ADI',\n",
    "       'OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "       'MACD_signal', '1D_past_return', '5D_past_return', '10D_past_return']) - all input features, that should \n",
    "       be included in the input array target_col (default = '5TD_return') - target variable, first \n",
    "       (newest) value for each input array\n",
    "    target_col - all columns that should be included in target_col\n",
    "        (default: target_col=['1D_past_return', '5D_past_return', '10D_past_return'])\n",
    "    outlier_validation - a dict that sets the outlier checks to be completed. Enter data in the format:\n",
    "        outlier_validation={'column_name': [lower_threshold, upper_threshold]} \n",
    "        Example: {'Stochastic': [0, 100], 'Stochastic_signal': [-10, 110], '5D_past_return': [-0.5, 0.5]}\n",
    "\n",
    "    Return tuple (input_array, target_array).\n",
    "\n",
    "    input_array dim: (number_of_samples x time_window x features_number)\n",
    "    target_array dim: (number_of_samples x time_window x returns_numbder)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## check to see if unsplit or train/test split dataframes provided\n",
    "    if unsplit_df is not None:\n",
    "        df = unsplit_df.copy()\n",
    "        if split_dataframe == True: \n",
    "            print('Train/Test Split: Splitting unsplit dataframe')\n",
    "            train_set, test_set = train_test_split_multiple_companies(unsplit_df, '3Y')\n",
    "        else:\n",
    "            print('Train/Test Split: Not splitting dataframe. (Holdout Data)')\n",
    "            train_set= df\n",
    "    elif (train_df is not None) and (test_df is not None):\n",
    "        print('Train/Test Split: Using provided train/test split dataframe')\n",
    "        df = train_df.copy()\n",
    "        train_set = train_df.copy()\n",
    "        test_set = test_df.copy()  \n",
    "    else:\n",
    "        print('''\n",
    "        Please enter valid input dataframes. Either: \n",
    "        --> Enter a unsplit dataframe (unsplit_df=df), or \n",
    "        --> Enter pre-split train and test dataframes (train_df=train and test_df=test)\n",
    "        ''')\n",
    "        return None, None, None, None, None\n",
    "        \n",
    "    \n",
    "    ## check to see if fitted scaler provided\n",
    "    if fitted_scaler == None:\n",
    "        print('Scaler: Fitting scaler on train set')\n",
    "        scaler = fit_train_scaler(train_set, outlier_validation=outlier_validation, input_cols=input_cols)\n",
    "    else:\n",
    "        print('Scaler: Using provided fitted_scaler')\n",
    "        scaler = fitted_scaler\n",
    "    \n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    stats2 = []\n",
    "    stats = {}\n",
    "    ## go company by company\n",
    "    print(f\"{df['ticker'].unique().size} Companies in Dataset\")\n",
    "    status_count = 0\n",
    "    for ticker in df['ticker'].unique():\n",
    "        status_count +=1\n",
    "        stats[ticker] = {}\n",
    "        print(f\"Starting {ticker}: Company {status_count} of {df['ticker'].unique().size}\")\n",
    "        train_outlier_count = 0\n",
    "        test_outlier_count = 0\n",
    "        company_train_x_array = []\n",
    "        company_train_y_array = []\n",
    "        \n",
    "        company_test_x_array = []\n",
    "        company_test_y_array = []\n",
    "\n",
    "        ## train\n",
    "        company_train_df = train_set[train_set['ticker'] == ticker]\n",
    "        company_train_sorted = company_train_df.sort_values('date', ascending=False)\n",
    "        company_train_sorted.reset_index(drop=True, inplace=True)\n",
    "        for row in range(0, len(company_train_sorted), stride):\n",
    "            outlier = False\n",
    "            df_slice = company_train_sorted.iloc[row: row + time_window].copy()\n",
    "            ## check for outliers\n",
    "            if check_train_outliers == True:\n",
    "                for k, v in outlier_validation.items(): \n",
    "                    if ((df_slice[k] < v[0]).any() == True) or ((df_slice[k] > v[1]).any() == True): outlier = True\n",
    "                \n",
    "            if df_slice.shape[0]==time_window and outlier==False:\n",
    "                ## scale the window\n",
    "                df_slice.loc[:, input_cols] = scaler.transform(df_slice[input_cols])\n",
    "                ## add to company array\n",
    "                company_train_x_array.append(np.array(df_slice[input_cols].values))\n",
    "                company_train_y_array.append(np.array(df_slice[target_col].iloc[0]))\n",
    "            else: train_outlier_count+=1\n",
    "        \n",
    "        if train_outlier_count/(len(company_train_sorted)/stride) <= outlier_threshold:\n",
    "            stats[ticker]['train_possible_windows'] = (len(company_train_sorted)/stride)\n",
    "            stats[ticker]['train_outliers'] = train_outlier_count\n",
    "            stats[ticker]['train_windows'] = len(company_train_x_array)\n",
    "            train_x.extend(company_train_x_array)\n",
    "            train_y.extend(company_train_y_array)\n",
    "            \n",
    "        \n",
    "        ## test\n",
    "        if split_dataframe == True:\n",
    "            company_test_df = test_set[test_set['ticker'] == ticker]\n",
    "            company_test_sorted = company_test_df.sort_values('date', ascending=False)\n",
    "            company_test_sorted.reset_index(drop=True, inplace=True)\n",
    "            for row in range(0, len(company_test_sorted), stride):\n",
    "                outlier = False\n",
    "                df_slice = company_test_sorted.iloc[row: row + time_window].copy()\n",
    "                ## check for outliers\n",
    "                if check_test_outliers == True:\n",
    "                    for k, v in outlier_validation.items(): \n",
    "                        if ((df_slice[k] < v[0]).any() == True) or ((df_slice[k] > v[1]).any() == True): outlier = True\n",
    "\n",
    "                if df_slice.shape[0]==time_window and outlier==False:\n",
    "                    ## scale the window\n",
    "                    df_slice.loc[:, input_cols] = scaler.transform(df_slice[input_cols])\n",
    "                    ## add to company array\n",
    "                    company_test_x_array.append(np.array(df_slice[input_cols].values))\n",
    "                    company_test_y_array.append(np.array(df_slice[target_col].iloc[0]))\n",
    "                else: test_outlier_count+=1\n",
    "\n",
    "            if train_outlier_count/(len(company_train_sorted)/stride) <= outlier_threshold:\n",
    "                stats[ticker]['test_possible_windows'] = (len(company_test_sorted)/stride)\n",
    "                stats[ticker]['test_outliers'] = test_outlier_count\n",
    "                stats[ticker]['test_windows'] = len(company_test_x_array)\n",
    "                test_x.extend(company_test_x_array)\n",
    "                test_y.extend(company_test_y_array)\n",
    "    \n",
    "    print('All Companies Completed')\n",
    "    print('')\n",
    "    ##print('Processing Stats:', stats)\n",
    "    \n",
    "    ## shuffle arrays\n",
    "    output_train_x = []\n",
    "    output_train_y = []\n",
    "    index_list = random.sample(range(len(train_x)), len(train_x))\n",
    "    for i in index_list:\n",
    "        output_train_x.append(train_x[i])\n",
    "        output_train_y.append(train_y[i])\n",
    "    if split_dataframe == True:\n",
    "        return np.array(output_train_x), np.array(output_train_y), np.array(test_x), np.array(test_y), scaler\n",
    "    else:\n",
    "        return np.array(output_train_x), np.array(output_train_y), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split: Splitting unsplit dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\mlchartist\\preprocessing.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.to_datetime(df['date'], format=('%Y-%m-%d'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: Using provided fitted_scaler\n",
      "3 Companies in Dataset\n",
      "Starting AAPL: Company 1 of 3\n",
      "Starting GOOGL: Company 2 of 3\n",
      "Starting AMZN: Company 3 of 3\n",
      "All Companies Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "              'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "TARGET_COLS=['5TD_return', '10TD_return', '20TD_return']\n",
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "\n",
    "stride = 100\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y, scaler = full_dataset_randomised_arrays_NEW(unsplit_df=joined_df, \n",
    "                                                                                #train_df=train_set, \n",
    "                                                                                #test_df=test_set, \n",
    "                                                                                stride=stride,\n",
    "                                                                                fitted_scaler=scaler,\n",
    "                                                                                split_dataframe=True,\n",
    "                                                                                input_cols=INPUT_COLS, \n",
    "                                                                                outlier_threshold=1, \n",
    "                                                                                outlier_validation=outlier_validation, \n",
    "                                                                                check_train_outliers=True,\n",
    "                                                                                check_test_outliers=True, \n",
    "                                                                                target_col=TARGET_COLS, \n",
    "                                                                                time_window=6,\n",
    "                                                                                test_set_size='3Y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split: Not splitting dataframe\n",
      "Scaler: Using provided fitted_scaler\n",
      "3 Companies in Dataset\n",
      "Starting AAPL: Company 1 of 3\n",
      "Starting GOOGL: Company 2 of 3\n",
      "Starting AMZN: Company 3 of 3\n",
      "All Companies Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "holdout_x, holdout_y, scaler = full_dataset_randomised_arrays_NEW(unsplit_df=joined_df, \n",
    "                                                                                #train_df=train_set, \n",
    "                                                                                #test_df=test_set, \n",
    "                                                                                stride=stride,\n",
    "                                                                                fitted_scaler=scaler,\n",
    "                                                                                split_dataframe=False,\n",
    "                                                                                input_cols=INPUT_COLS, \n",
    "                                                                                outlier_threshold=1, \n",
    "                                                                                outlier_validation=outlier_validation, \n",
    "                                                                                check_train_outliers=True,\n",
    "                                                                                check_test_outliers=True, \n",
    "                                                                                target_col=TARGET_COLS, \n",
    "                                                                                time_window=6,\n",
    "                                                                                test_set_size='3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Stats ###\n",
      "train_x (170, 6, 15)\n",
      "train_y (170, 3)\n",
      "test_x (24, 6, 15)\n",
      "test_y (24, 3)\n",
      "scaler RobustScaler()\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('train_x', train_x.shape)\n",
    "print('train_y', train_y.shape)\n",
    "print('test_x', test_x.shape)\n",
    "print('test_y', test_y.shape)\n",
    "print('scaler', scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Stats ###\n",
      "holdout_x (192, 6, 15)\n",
      "holdout_y (192, 3)\n",
      "scaler RobustScaler()\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('holdout_x', holdout_x.shape)\n",
    "print('holdout_y', holdout_y.shape)\n",
    "print('scaler', scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
