{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mlchartist.array_builder import build_arrays\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/processed/aapl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIVE_TR = 0.0006\n",
    "TEN_TR = 0.0012\n",
    "TWENTY_TR = 0.0024\n",
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI',\n",
    "       'OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "       'MACD_signal', '1D_past_return', '5D_past_return', '10D_past_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['5D_return_bin'] = (df['5TD_return'] >= FIVE_TR)\n",
    "df['10D_return_bin'] = (df['10TD_return'] >= TEN_TR)\n",
    "df['20D_return_bin'] = (df['20TD_return'] >= TWENTY_TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['date'].dt.year >= 2018]\n",
    "train_df = df[df['date'].dt.year < 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(train_df[INPUT_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "train_df.loc[:, INPUT_COLS] = scaler.transform(train_df[INPUT_COLS])\n",
    "test_df.loc[:, INPUT_COLS] = scaler.transform(test_df[INPUT_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stochastic</th>\n",
       "      <th>Stochastic_signal</th>\n",
       "      <th>ADI</th>\n",
       "      <th>OBV</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADX_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>5TD_return</th>\n",
       "      <th>10TD_return</th>\n",
       "      <th>20TD_return</th>\n",
       "      <th>1D_past_return</th>\n",
       "      <th>5D_past_return</th>\n",
       "      <th>10D_past_return</th>\n",
       "      <th>5D_return_bin</th>\n",
       "      <th>10D_return_bin</th>\n",
       "      <th>20D_return_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1984-10-24</td>\n",
       "      <td>0.559329</td>\n",
       "      <td>0.766901</td>\n",
       "      <td>0.699902</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.180156</td>\n",
       "      <td>0.473094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469507</td>\n",
       "      <td>-0.052010</td>\n",
       "      <td>-0.018263</td>\n",
       "      <td>-0.119206</td>\n",
       "      <td>0.620211</td>\n",
       "      <td>0.513346</td>\n",
       "      <td>0.493851</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1984-10-25</td>\n",
       "      <td>0.444474</td>\n",
       "      <td>0.566252</td>\n",
       "      <td>0.688816</td>\n",
       "      <td>0.377434</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.164365</td>\n",
       "      <td>0.429957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469642</td>\n",
       "      <td>-0.009378</td>\n",
       "      <td>-0.022156</td>\n",
       "      <td>-0.060181</td>\n",
       "      <td>0.565985</td>\n",
       "      <td>0.459435</td>\n",
       "      <td>0.471151</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1984-10-26</td>\n",
       "      <td>0.381803</td>\n",
       "      <td>0.433748</td>\n",
       "      <td>0.593763</td>\n",
       "      <td>0.376582</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.400033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469734</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>-0.055397</td>\n",
       "      <td>-0.026218</td>\n",
       "      <td>0.579590</td>\n",
       "      <td>0.439518</td>\n",
       "      <td>0.485339</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1984-10-29</td>\n",
       "      <td>0.391002</td>\n",
       "      <td>0.449973</td>\n",
       "      <td>0.487260</td>\n",
       "      <td>0.376098</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>0.390144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025925</td>\n",
       "      <td>-0.003162</td>\n",
       "      <td>0.612989</td>\n",
       "      <td>0.446934</td>\n",
       "      <td>0.448101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1984-10-30</td>\n",
       "      <td>0.429286</td>\n",
       "      <td>0.517036</td>\n",
       "      <td>0.470721</td>\n",
       "      <td>0.375384</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.117606</td>\n",
       "      <td>0.422118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469852</td>\n",
       "      <td>0.048060</td>\n",
       "      <td>-0.060959</td>\n",
       "      <td>0.035265</td>\n",
       "      <td>0.624619</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.459589</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>0.593111</td>\n",
       "      <td>0.797292</td>\n",
       "      <td>0.783504</td>\n",
       "      <td>0.960121</td>\n",
       "      <td>0.957650</td>\n",
       "      <td>0.544299</td>\n",
       "      <td>0.121701</td>\n",
       "      <td>0.337513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655031</td>\n",
       "      <td>-0.015700</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>0.609262</td>\n",
       "      <td>0.474210</td>\n",
       "      <td>0.450176</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8360</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>0.410739</td>\n",
       "      <td>0.384139</td>\n",
       "      <td>0.664945</td>\n",
       "      <td>0.960100</td>\n",
       "      <td>0.957135</td>\n",
       "      <td>0.592268</td>\n",
       "      <td>0.119645</td>\n",
       "      <td>0.277601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649232</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.579450</td>\n",
       "      <td>0.442956</td>\n",
       "      <td>0.419257</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>0.411871</td>\n",
       "      <td>0.215735</td>\n",
       "      <td>0.469514</td>\n",
       "      <td>0.960571</td>\n",
       "      <td>0.957468</td>\n",
       "      <td>0.567239</td>\n",
       "      <td>0.117737</td>\n",
       "      <td>0.266940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637252</td>\n",
       "      <td>0.014352</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.609462</td>\n",
       "      <td>0.451533</td>\n",
       "      <td>0.423216</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>0.432128</td>\n",
       "      <td>0.275111</td>\n",
       "      <td>0.294037</td>\n",
       "      <td>0.960519</td>\n",
       "      <td>0.957724</td>\n",
       "      <td>0.549103</td>\n",
       "      <td>0.108072</td>\n",
       "      <td>0.301668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.022789</td>\n",
       "      <td>0.034936</td>\n",
       "      <td>-0.018294</td>\n",
       "      <td>0.612698</td>\n",
       "      <td>0.454563</td>\n",
       "      <td>0.422902</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>0.365784</td>\n",
       "      <td>0.052944</td>\n",
       "      <td>0.182739</td>\n",
       "      <td>0.959640</td>\n",
       "      <td>0.957321</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.106776</td>\n",
       "      <td>0.280518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603070</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>0.041192</td>\n",
       "      <td>-0.013338</td>\n",
       "      <td>0.596442</td>\n",
       "      <td>0.443138</td>\n",
       "      <td>0.415735</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8364 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker       date       RSI  Stochastic  Stochastic_signal       ADI  \\\n",
       "0      AAPL 1984-10-24  0.559329    0.766901           0.699902  0.378947   \n",
       "1      AAPL 1984-10-25  0.444474    0.566252           0.688816  0.377434   \n",
       "2      AAPL 1984-10-26  0.381803    0.433748           0.593763  0.376582   \n",
       "3      AAPL 1984-10-29  0.391002    0.449973           0.487260  0.376098   \n",
       "4      AAPL 1984-10-30  0.429286    0.517036           0.470721  0.375384   \n",
       "...     ...        ...       ...         ...                ...       ...   \n",
       "8359   AAPL 2017-12-22  0.593111    0.797292           0.783504  0.960121   \n",
       "8360   AAPL 2017-12-26  0.410739    0.384139           0.664945  0.960100   \n",
       "8361   AAPL 2017-12-27  0.411871    0.215735           0.469514  0.960571   \n",
       "8362   AAPL 2017-12-28  0.432128    0.275111           0.294037  0.960519   \n",
       "8363   AAPL 2017-12-29  0.365784    0.052944           0.182739  0.959640   \n",
       "\n",
       "           OBV       ATR       ADX   ADX_pos  ...  MACD_signal  5TD_return  \\\n",
       "0     0.010414  0.001976  0.180156  0.473094  ...     0.469507   -0.052010   \n",
       "1     0.009730  0.002004  0.164365  0.429957  ...     0.469642   -0.009378   \n",
       "2     0.009233  0.001966  0.148936  0.400033  ...     0.469734    0.009726   \n",
       "3     0.009452  0.001805  0.134610  0.390144  ...     0.469797    0.000000   \n",
       "4     0.009775  0.001739  0.117606  0.422118  ...     0.469852    0.048060   \n",
       "...        ...       ...       ...       ...  ...          ...         ...   \n",
       "8359  0.957650  0.544299  0.121701  0.337513  ...     0.655031   -0.015700   \n",
       "8360  0.957135  0.592268  0.119645  0.277601  ...     0.649232    0.009748   \n",
       "8361  0.957468  0.567239  0.117737  0.266940  ...     0.637252    0.014352   \n",
       "8362  0.957724  0.549103  0.108072  0.301668  ...     0.622642    0.022789   \n",
       "8363  0.957321  0.540500  0.106776  0.280518  ...     0.603070    0.030556   \n",
       "\n",
       "      10TD_return  20TD_return  1D_past_return  5D_past_return  \\\n",
       "0       -0.018263    -0.119206        0.620211        0.513346   \n",
       "1       -0.022156    -0.060181        0.565985        0.459435   \n",
       "2       -0.055397    -0.026218        0.579590        0.439518   \n",
       "3       -0.025925    -0.003162        0.612989        0.446934   \n",
       "4       -0.060959     0.035265        0.624619        0.439981   \n",
       "...           ...          ...             ...             ...   \n",
       "8359    -0.003848    -0.004489        0.609262        0.474210   \n",
       "8360     0.021836     0.003290        0.579450        0.442956   \n",
       "8361     0.027485     0.005360        0.609462        0.451533   \n",
       "8362     0.034936    -0.018294        0.612698        0.454563   \n",
       "8363     0.041192    -0.013338        0.596442        0.443138   \n",
       "\n",
       "      10D_past_return  5D_return_bin  10D_return_bin  20D_return_bin  \n",
       "0            0.493851          False           False           False  \n",
       "1            0.471151          False           False           False  \n",
       "2            0.485339           True           False           False  \n",
       "3            0.448101          False           False           False  \n",
       "4            0.459589           True           False            True  \n",
       "...               ...            ...             ...             ...  \n",
       "8359         0.450176          False           False           False  \n",
       "8360         0.419257           True            True            True  \n",
       "8361         0.423216           True            True            True  \n",
       "8362         0.422902           True            True           False  \n",
       "8363         0.415735           True            True           False  \n",
       "\n",
       "[8364 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = build_arrays(train_df, target_col='10D_return_bin', time_window=14, stride=1)\n",
    "X_test, y_test = build_arrays(test_df, target_col='10D_return_bin', time_window=14, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8351, 14, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers \n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.LSTM(500, return_sequences=True, input_shape=(14,15)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(500, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(500, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(500, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(500, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(500))\n",
    "    model.add(layers.Dense(300))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(300))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "209/209 [==============================] - 58s 280ms/step - loss: 0.8484 - accuracy: 0.5232 - val_loss: 0.6904 - val_accuracy: 0.5428\n",
      "Epoch 2/200\n",
      "209/209 [==============================] - 58s 277ms/step - loss: 0.6909 - accuracy: 0.5437 - val_loss: 0.6895 - val_accuracy: 0.5428\n",
      "Epoch 3/200\n",
      "209/209 [==============================] - 59s 281ms/step - loss: 0.6900 - accuracy: 0.5430 - val_loss: 0.6913 - val_accuracy: 0.5428\n",
      "Epoch 4/200\n",
      "209/209 [==============================] - 58s 279ms/step - loss: 0.6903 - accuracy: 0.5425 - val_loss: 0.6896 - val_accuracy: 0.5428\n",
      "Epoch 5/200\n",
      "209/209 [==============================] - 58s 279ms/step - loss: 0.6898 - accuracy: 0.5422 - val_loss: 0.6895 - val_accuracy: 0.5428\n",
      "Epoch 6/200\n",
      "209/209 [==============================] - 58s 279ms/step - loss: 0.6900 - accuracy: 0.5452 - val_loss: 0.6895 - val_accuracy: 0.5428\n",
      "Epoch 7/200\n",
      "209/209 [==============================] - 59s 280ms/step - loss: 0.6894 - accuracy: 0.5449 - val_loss: 0.6939 - val_accuracy: 0.5428\n",
      "Epoch 8/200\n",
      "209/209 [==============================] - 59s 282ms/step - loss: 0.6902 - accuracy: 0.5457 - val_loss: 0.6897 - val_accuracy: 0.5428\n",
      "Epoch 9/200\n",
      "209/209 [==============================] - 59s 281ms/step - loss: 0.6899 - accuracy: 0.5446 - val_loss: 0.6897 - val_accuracy: 0.5428\n",
      "Epoch 10/200\n",
      "209/209 [==============================] - 59s 280ms/step - loss: 0.6897 - accuracy: 0.5428 - val_loss: 0.6910 - val_accuracy: 0.5428\n",
      "Epoch 11/200\n",
      "209/209 [==============================] - 58s 280ms/step - loss: 0.6899 - accuracy: 0.5457 - val_loss: 0.6896 - val_accuracy: 0.5428\n",
      "Epoch 12/200\n",
      "209/209 [==============================] - 59s 281ms/step - loss: 0.6897 - accuracy: 0.5457 - val_loss: 0.6897 - val_accuracy: 0.5428\n",
      "Epoch 13/200\n",
      "209/209 [==============================] - 59s 282ms/step - loss: 0.6898 - accuracy: 0.5457 - val_loss: 0.6896 - val_accuracy: 0.5428\n",
      "Epoch 14/200\n",
      "209/209 [==============================] - 58s 276ms/step - loss: 0.6898 - accuracy: 0.5457 - val_loss: 0.6896 - val_accuracy: 0.5428\n",
      "Epoch 15/200\n",
      "209/209 [==============================] - 57s 270ms/step - loss: 0.6895 - accuracy: 0.5454 - val_loss: 0.6896 - val_accuracy: 0.5428\n",
      "Epoch 16/200\n",
      "209/209 [==============================] - 57s 271ms/step - loss: 0.6895 - accuracy: 0.5457 - val_loss: 0.6901 - val_accuracy: 0.5428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1c1010df50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_model()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=200, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 63ms/step - loss: 0.6701 - accuracy: 0.6721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6700549721717834, 0.6720867156982422]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6720867208672087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
