{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from mlchartist.array_builder import build_arrays, build_randomised_arrays\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/processed/aapl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIVE_TR = 0.0006\n",
    "TEN_TR = 0.0012\n",
    "TWENTY_TR = 0.0024\n",
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff','MACD_signal', '1D_past_return', '5D_past_return', '10D_past_return']\n",
    "#INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['5D_return_bin'] = (df['5TD_return'] >= FIVE_TR)\n",
    "df['10D_return_bin'] = (df['10TD_return'] >= TEN_TR)\n",
    "df['20D_return_bin'] = (df['20TD_return'] >= TWENTY_TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[(df['date'].dt.year >= 2017) & (df['date'].dt.year <= 2019)]\n",
    "train_df = df[(df['date'].dt.year >= 1995) & (df['date'].dt.year < 2017)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(train_df[INPUT_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "train_df.loc[:, INPUT_COLS] = scaler.transform(train_df[INPUT_COLS])\n",
    "test_df.loc[:, INPUT_COLS] = scaler.transform(test_df[INPUT_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stochastic</th>\n",
       "      <th>Stochastic_signal</th>\n",
       "      <th>ADI</th>\n",
       "      <th>OBV</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADX_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>5TD_return</th>\n",
       "      <th>10TD_return</th>\n",
       "      <th>20TD_return</th>\n",
       "      <th>1D_past_return</th>\n",
       "      <th>5D_past_return</th>\n",
       "      <th>10D_past_return</th>\n",
       "      <th>5D_return_bin</th>\n",
       "      <th>10D_return_bin</th>\n",
       "      <th>20D_return_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1995-01-03</td>\n",
       "      <td>-0.276126</td>\n",
       "      <td>0.130640</td>\n",
       "      <td>0.760803</td>\n",
       "      <td>-0.973950</td>\n",
       "      <td>-1.750625</td>\n",
       "      <td>-0.787427</td>\n",
       "      <td>-1.116899</td>\n",
       "      <td>0.127035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177532</td>\n",
       "      <td>0.137530</td>\n",
       "      <td>0.171710</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>-0.564551</td>\n",
       "      <td>-0.284328</td>\n",
       "      <td>0.207511</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1995-01-04</td>\n",
       "      <td>0.206404</td>\n",
       "      <td>0.987085</td>\n",
       "      <td>0.678144</td>\n",
       "      <td>-0.971123</td>\n",
       "      <td>-1.747888</td>\n",
       "      <td>-0.787424</td>\n",
       "      <td>-1.142106</td>\n",
       "      <td>0.414668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175352</td>\n",
       "      <td>0.186767</td>\n",
       "      <td>0.157210</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>0.853992</td>\n",
       "      <td>0.014979</td>\n",
       "      <td>-0.058760</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1995-01-05</td>\n",
       "      <td>-0.083517</td>\n",
       "      <td>0.394701</td>\n",
       "      <td>0.538988</td>\n",
       "      <td>-0.972516</td>\n",
       "      <td>-1.749158</td>\n",
       "      <td>-0.789080</td>\n",
       "      <td>-1.165512</td>\n",
       "      <td>0.282975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173616</td>\n",
       "      <td>0.168014</td>\n",
       "      <td>0.180473</td>\n",
       "      <td>0.070379</td>\n",
       "      <td>-0.509115</td>\n",
       "      <td>-0.197944</td>\n",
       "      <td>-0.028111</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1995-01-06</td>\n",
       "      <td>1.011928</td>\n",
       "      <td>0.873063</td>\n",
       "      <td>0.803622</td>\n",
       "      <td>-0.976448</td>\n",
       "      <td>-1.730592</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>-0.982966</td>\n",
       "      <td>1.817740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170235</td>\n",
       "      <td>0.068410</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>-0.036508</td>\n",
       "      <td>2.735552</td>\n",
       "      <td>0.883627</td>\n",
       "      <td>0.894121</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1995-01-09</td>\n",
       "      <td>0.623690</td>\n",
       "      <td>0.387398</td>\n",
       "      <td>0.589865</td>\n",
       "      <td>-0.980846</td>\n",
       "      <td>-1.735318</td>\n",
       "      <td>-0.780756</td>\n",
       "      <td>-0.824343</td>\n",
       "      <td>1.570206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166525</td>\n",
       "      <td>0.079660</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>-0.017867</td>\n",
       "      <td>-0.697859</td>\n",
       "      <td>0.790160</td>\n",
       "      <td>0.601116</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8108</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>0.916686</td>\n",
       "      <td>1.081715</td>\n",
       "      <td>1.219224</td>\n",
       "      <td>1.336925</td>\n",
       "      <td>1.107500</td>\n",
       "      <td>1.259392</td>\n",
       "      <td>-0.214894</td>\n",
       "      <td>-0.034720</td>\n",
       "      <td>...</td>\n",
       "      <td>1.225535</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>0.022144</td>\n",
       "      <td>0.045883</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>-0.022024</td>\n",
       "      <td>0.112079</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>1.110562</td>\n",
       "      <td>1.244353</td>\n",
       "      <td>1.198237</td>\n",
       "      <td>1.337231</td>\n",
       "      <td>1.108599</td>\n",
       "      <td>1.230710</td>\n",
       "      <td>-0.191890</td>\n",
       "      <td>0.456505</td>\n",
       "      <td>...</td>\n",
       "      <td>1.334865</td>\n",
       "      <td>-0.010410</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.169578</td>\n",
       "      <td>-0.017361</td>\n",
       "      <td>0.245686</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>0.848563</td>\n",
       "      <td>0.899185</td>\n",
       "      <td>1.149520</td>\n",
       "      <td>1.336436</td>\n",
       "      <td>1.107386</td>\n",
       "      <td>1.252774</td>\n",
       "      <td>-0.197010</td>\n",
       "      <td>0.186792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416748</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.044417</td>\n",
       "      <td>-0.185915</td>\n",
       "      <td>-0.122105</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>0.841578</td>\n",
       "      <td>0.727793</td>\n",
       "      <td>1.023366</td>\n",
       "      <td>1.336398</td>\n",
       "      <td>1.106459</td>\n",
       "      <td>1.169928</td>\n",
       "      <td>-0.201763</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473255</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>-0.046739</td>\n",
       "      <td>-0.137891</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>0.343438</td>\n",
       "      <td>0.157683</td>\n",
       "      <td>0.636025</td>\n",
       "      <td>1.334571</td>\n",
       "      <td>1.104538</td>\n",
       "      <td>1.191186</td>\n",
       "      <td>-0.295319</td>\n",
       "      <td>-0.153640</td>\n",
       "      <td>...</td>\n",
       "      <td>1.488639</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>0.036028</td>\n",
       "      <td>0.047843</td>\n",
       "      <td>-0.318821</td>\n",
       "      <td>-0.161460</td>\n",
       "      <td>-0.137348</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5537 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker       date       RSI  Stochastic  Stochastic_signal       ADI  \\\n",
       "2576   AAPL 1995-01-03 -0.276126    0.130640           0.760803 -0.973950   \n",
       "2577   AAPL 1995-01-04  0.206404    0.987085           0.678144 -0.971123   \n",
       "2578   AAPL 1995-01-05 -0.083517    0.394701           0.538988 -0.972516   \n",
       "2579   AAPL 1995-01-06  1.011928    0.873063           0.803622 -0.976448   \n",
       "2580   AAPL 1995-01-09  0.623690    0.387398           0.589865 -0.980846   \n",
       "...     ...        ...       ...         ...                ...       ...   \n",
       "8108   AAPL 2016-12-23  0.916686    1.081715           1.219224  1.336925   \n",
       "8109   AAPL 2016-12-27  1.110562    1.244353           1.198237  1.337231   \n",
       "8110   AAPL 2016-12-28  0.848563    0.899185           1.149520  1.336436   \n",
       "8111   AAPL 2016-12-29  0.841578    0.727793           1.023366  1.336398   \n",
       "8112   AAPL 2016-12-30  0.343438    0.157683           0.636025  1.334571   \n",
       "\n",
       "           OBV       ATR       ADX   ADX_pos  ...  MACD_signal  5TD_return  \\\n",
       "2576 -1.750625 -0.787427 -1.116899  0.127035  ...    -0.177532    0.137530   \n",
       "2577 -1.747888 -0.787424 -1.142106  0.414668  ...    -0.175352    0.186767   \n",
       "2578 -1.749158 -0.789080 -1.165512  0.282975  ...    -0.173616    0.168014   \n",
       "2579 -1.730592 -0.779607 -0.982966  1.817740  ...    -0.170235    0.068410   \n",
       "2580 -1.735318 -0.780756 -0.824343  1.570206  ...    -0.166525    0.079660   \n",
       "...        ...       ...       ...       ...  ...          ...         ...   \n",
       "8108  1.107500  1.259392 -0.214894 -0.034720  ...     1.225535   -0.003226   \n",
       "8109  1.108599  1.230710 -0.191890  0.456505  ...     1.334865   -0.010410   \n",
       "8110  1.107386  1.252774 -0.197010  0.186792  ...     1.416748   -0.001194   \n",
       "8111  1.106459  1.169928 -0.201763  0.085747  ...     1.473255    0.009876   \n",
       "8112  1.104538  1.191186 -0.295319 -0.153640  ...     1.488639    0.027349   \n",
       "\n",
       "      10TD_return  20TD_return  1D_past_return  5D_past_return  \\\n",
       "2576     0.171710     0.051861       -0.564551       -0.284328   \n",
       "2577     0.157210     0.018156        0.853992        0.014979   \n",
       "2578     0.180473     0.070379       -0.509115       -0.197944   \n",
       "2579     0.014344    -0.036508        2.735552        0.883627   \n",
       "2580     0.025272    -0.017867       -0.697859        0.790160   \n",
       "...           ...          ...             ...             ...   \n",
       "8108     0.022144     0.045883        0.025916       -0.022024   \n",
       "8109     0.021288     0.039983        0.169578       -0.017361   \n",
       "8110     0.021413     0.044417       -0.185915       -0.122105   \n",
       "8111     0.019606     0.041637       -0.046739       -0.137891   \n",
       "8112     0.036028     0.047843       -0.318821       -0.161460   \n",
       "\n",
       "      10D_past_return  5D_return_bin  10D_return_bin  20D_return_bin  \n",
       "2576         0.207511           True            True            True  \n",
       "2577        -0.058760           True            True            True  \n",
       "2578        -0.028111           True            True            True  \n",
       "2579         0.894121           True            True           False  \n",
       "2580         0.601116           True            True           False  \n",
       "...               ...            ...             ...             ...  \n",
       "8108         0.112079          False            True            True  \n",
       "8109         0.245686          False            True            True  \n",
       "8110         0.014513          False            True            True  \n",
       "8111         0.013302           True            True            True  \n",
       "8112        -0.137348           True            True            True  \n",
       "\n",
       "[5537 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_train_x_20, apple_train_y_20 = build_arrays(train_df,input_cols=INPUT_COLS, target_col='20D_return_bin', time_window=40, stride=1)\n",
    "apple_test_x_20, apple_test_y_20 = build_arrays(test_df,input_cols=INPUT_COLS, target_col='20D_return_bin', time_window=40, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = list(range(len(apple_train_x_20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5498"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754, 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indx = random.sample(indx, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_20 =  apple_train_x_20[[sample_indx], :][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_train_20 = apple_train_y_20[[sample_indx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers, models \n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "optim = RMSprop(learning_rate=0.0001)\n",
    "precision = Precision()\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    reg_l1 = regularizers.l1(0.001)\n",
    "    reg_l2 = regularizers.l2(0.001)\n",
    "    reg_l1_l2 = regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "    model.add(layers.LSTM(200, return_sequences=True, input_shape=(40,15), activation='tanh'))\n",
    "    model.add(layers.LSTM(200, activation='tanh'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(200, activation='relu', kernel_regularizer=reg_l1))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(100, activation='relu', bias_regularizer=reg_l2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(50, activation='relu', activity_regularizer=reg_l1_l2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=[precision, 'accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 20 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 2.7492 - precision: 0.6261 - accuracy: 0.5748 - val_loss: 2.4251 - val_precision: 0.6182 - val_accuracy: 0.6130\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 2.1587 - precision: 0.6048 - accuracy: 0.6025 - val_loss: 1.9205 - val_precision: 0.6374 - val_accuracy: 0.6200\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.7159 - precision: 0.6415 - accuracy: 0.6263 - val_loss: 1.5365 - val_precision: 0.6955 - val_accuracy: 0.6670\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.3912 - precision: 0.6809 - accuracy: 0.6540 - val_loss: 1.2922 - val_precision: 0.6656 - val_accuracy: 0.6330\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 1.1556 - precision: 0.6941 - accuracy: 0.6680 - val_loss: 1.0673 - val_precision: 0.6840 - val_accuracy: 0.6500\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.9889 - precision: 0.7022 - accuracy: 0.6798 - val_loss: 0.9342 - val_precision: 0.6839 - val_accuracy: 0.6580\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.8673 - precision: 0.7072 - accuracy: 0.6888 - val_loss: 0.8463 - val_precision: 0.7008 - val_accuracy: 0.6660\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.7831 - precision: 0.7276 - accuracy: 0.7088 - val_loss: 0.7642 - val_precision: 0.7134 - val_accuracy: 0.6940\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.7288 - precision: 0.7288 - accuracy: 0.7120 - val_loss: 0.7202 - val_precision: 0.7228 - val_accuracy: 0.6930\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6856 - precision: 0.7507 - accuracy: 0.7325 - val_loss: 0.6875 - val_precision: 0.7315 - val_accuracy: 0.7040\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6464 - precision: 0.7512 - accuracy: 0.7393 - val_loss: 0.6789 - val_precision: 0.7433 - val_accuracy: 0.6940\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6140 - precision: 0.7688 - accuracy: 0.7550 - val_loss: 0.6205 - val_precision: 0.7568 - val_accuracy: 0.7460\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.5882 - precision: 0.7791 - accuracy: 0.7648 - val_loss: 0.6050 - val_precision: 0.7632 - val_accuracy: 0.7320\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5603 - precision: 0.7901 - accuracy: 0.7750 - val_loss: 0.5754 - val_precision: 0.7844 - val_accuracy: 0.7660\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5376 - precision: 0.8099 - accuracy: 0.7933 - val_loss: 0.5593 - val_precision: 0.8156 - val_accuracy: 0.7720\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5136 - precision: 0.8177 - accuracy: 0.8030 - val_loss: 0.5395 - val_precision: 0.7828 - val_accuracy: 0.7850\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4972 - precision: 0.8283 - accuracy: 0.8158 - val_loss: 0.5142 - val_precision: 0.8030 - val_accuracy: 0.7920\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4736 - precision: 0.8404 - accuracy: 0.8290 - val_loss: 0.5315 - val_precision: 0.8540 - val_accuracy: 0.7770\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4582 - precision: 0.8541 - accuracy: 0.8397 - val_loss: 0.4784 - val_precision: 0.8595 - val_accuracy: 0.8220\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4444 - precision: 0.8499 - accuracy: 0.8375 - val_loss: 0.4733 - val_precision: 0.8498 - val_accuracy: 0.8190\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.4297 - precision: 0.8589 - accuracy: 0.8533 - val_loss: 0.4544 - val_precision: 0.8711 - val_accuracy: 0.8320\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4152 - precision: 0.8677 - accuracy: 0.8597 - val_loss: 0.4475 - val_precision: 0.8293 - val_accuracy: 0.8320\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4099 - precision: 0.8616 - accuracy: 0.8612 - val_loss: 0.4369 - val_precision: 0.8730 - val_accuracy: 0.8400\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3896 - precision: 0.8810 - accuracy: 0.8698 - val_loss: 0.4245 - val_precision: 0.8540 - val_accuracy: 0.8450\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3791 - precision: 0.8691 - accuracy: 0.8633 - val_loss: 0.4420 - val_precision: 0.8567 - val_accuracy: 0.8460\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3741 - precision: 0.8836 - accuracy: 0.8745 - val_loss: 0.4309 - val_precision: 0.8467 - val_accuracy: 0.8480\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3696 - precision: 0.8855 - accuracy: 0.8742 - val_loss: 0.4465 - val_precision: 0.8475 - val_accuracy: 0.8470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe7d011f290>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20 = init_model()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model_20.fit(X_train_20, y_train_20, \n",
    "          epochs=500, \n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5725718443070207"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_train_y_20.sum()/len(apple_train_y_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6853146853146853"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_test_y_20.sum()/len(apple_test_y_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 1.3471 - precision: 0.7056 - accuracy: 0.5217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3471311330795288, 0.7055555582046509, 0.5216783285140991]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20.evaluate(apple_test_x_20, apple_test_y_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 10 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_train_x_10, apple_train_y_10 = build_arrays(train_df,input_cols=INPUT_COLS, target_col='10D_return_bin', time_window=40, stride=1)\n",
    "apple_test_x_10, apple_test_y_10 = build_arrays(test_df,input_cols=INPUT_COLS, target_col='10D_return_bin', time_window=40, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train_10 =  apple_train_x_10[[sample_indx], :][0]\n",
    "y_train_10 = apple_train_y_10[[sample_indx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 2.7798 - precision: 0.5850 - accuracy: 0.5353 - val_loss: 2.4436 - val_precision: 0.5895 - val_accuracy: 0.6000\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 2.1739 - precision: 0.5843 - accuracy: 0.5842 - val_loss: 1.9221 - val_precision: 0.6066 - val_accuracy: 0.5950\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.7233 - precision: 0.5906 - accuracy: 0.5855 - val_loss: 1.5379 - val_precision: 0.6279 - val_accuracy: 0.6040\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 1.3917 - precision: 0.6082 - accuracy: 0.5995 - val_loss: 1.2577 - val_precision: 0.6282 - val_accuracy: 0.6210\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.1550 - precision: 0.6167 - accuracy: 0.6137 - val_loss: 1.0612 - val_precision: 0.6361 - val_accuracy: 0.6200\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.9899 - precision: 0.6338 - accuracy: 0.6308 - val_loss: 0.9261 - val_precision: 0.6390 - val_accuracy: 0.6330\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.8740 - precision: 0.6445 - accuracy: 0.6447 - val_loss: 0.8589 - val_precision: 0.6493 - val_accuracy: 0.6170\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.7995 - precision: 0.6485 - accuracy: 0.6518 - val_loss: 0.7816 - val_precision: 0.6594 - val_accuracy: 0.6450\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.7530 - precision: 0.6534 - accuracy: 0.6587 - val_loss: 0.7561 - val_precision: 0.6328 - val_accuracy: 0.6380\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.7178 - precision: 0.6647 - accuracy: 0.6690 - val_loss: 0.7222 - val_precision: 0.6767 - val_accuracy: 0.6620\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6899 - precision: 0.6730 - accuracy: 0.6833 - val_loss: 0.6999 - val_precision: 0.6546 - val_accuracy: 0.6610\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6678 - precision: 0.6863 - accuracy: 0.6965 - val_loss: 0.7002 - val_precision: 0.6913 - val_accuracy: 0.6670\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6488 - precision: 0.6909 - accuracy: 0.7007 - val_loss: 0.7018 - val_precision: 0.6696 - val_accuracy: 0.6680\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6320 - precision: 0.7036 - accuracy: 0.7132 - val_loss: 0.6565 - val_precision: 0.7069 - val_accuracy: 0.7030\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6133 - precision: 0.7126 - accuracy: 0.7193 - val_loss: 0.6398 - val_precision: 0.7333 - val_accuracy: 0.7190\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6016 - precision: 0.7198 - accuracy: 0.7232 - val_loss: 0.6241 - val_precision: 0.7390 - val_accuracy: 0.7100\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5801 - precision: 0.7421 - accuracy: 0.7398 - val_loss: 0.6122 - val_precision: 0.7560 - val_accuracy: 0.7160\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.5732 - precision: 0.7571 - accuracy: 0.7492 - val_loss: 0.6093 - val_precision: 0.7518 - val_accuracy: 0.7250\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5565 - precision: 0.7635 - accuracy: 0.7582 - val_loss: 0.5870 - val_precision: 0.7375 - val_accuracy: 0.7340\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5401 - precision: 0.7824 - accuracy: 0.7715 - val_loss: 0.5782 - val_precision: 0.7952 - val_accuracy: 0.7560\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.5308 - precision: 0.7961 - accuracy: 0.7807 - val_loss: 0.5677 - val_precision: 0.7687 - val_accuracy: 0.7550\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5154 - precision: 0.7993 - accuracy: 0.7865 - val_loss: 0.5434 - val_precision: 0.7815 - val_accuracy: 0.7740\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.4941 - precision: 0.8201 - accuracy: 0.8052 - val_loss: 0.5409 - val_precision: 0.8178 - val_accuracy: 0.7740\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4884 - precision: 0.8288 - accuracy: 0.8095 - val_loss: 0.5547 - val_precision: 0.8091 - val_accuracy: 0.7660\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4722 - precision: 0.8372 - accuracy: 0.8177 - val_loss: 0.5345 - val_precision: 0.8115 - val_accuracy: 0.7630\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4610 - precision: 0.8508 - accuracy: 0.8253 - val_loss: 0.5047 - val_precision: 0.8046 - val_accuracy: 0.7820\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4517 - precision: 0.8530 - accuracy: 0.8320 - val_loss: 0.5084 - val_precision: 0.8566 - val_accuracy: 0.7920\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4352 - precision: 0.8621 - accuracy: 0.8390 - val_loss: 0.5000 - val_precision: 0.8037 - val_accuracy: 0.7980\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4295 - precision: 0.8590 - accuracy: 0.8410 - val_loss: 0.4768 - val_precision: 0.8346 - val_accuracy: 0.8030\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4127 - precision: 0.8741 - accuracy: 0.8530 - val_loss: 0.4679 - val_precision: 0.8428 - val_accuracy: 0.8140\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.4153 - precision: 0.8702 - accuracy: 0.8510 - val_loss: 0.4648 - val_precision: 0.8245 - val_accuracy: 0.8050\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3944 - precision: 0.8768 - accuracy: 0.8587 - val_loss: 0.4665 - val_precision: 0.8480 - val_accuracy: 0.8190\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3899 - precision: 0.8737 - accuracy: 0.8645 - val_loss: 0.4315 - val_precision: 0.8408 - val_accuracy: 0.8200\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3850 - precision: 0.8820 - accuracy: 0.8648 - val_loss: 0.4469 - val_precision: 0.8664 - val_accuracy: 0.8230\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3750 - precision: 0.8822 - accuracy: 0.8702 - val_loss: 0.4466 - val_precision: 0.8526 - val_accuracy: 0.8170\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3639 - precision: 0.8851 - accuracy: 0.8742 - val_loss: 0.4217 - val_precision: 0.8490 - val_accuracy: 0.8320\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3584 - precision: 0.8893 - accuracy: 0.8742 - val_loss: 0.4291 - val_precision: 0.8582 - val_accuracy: 0.8430\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3511 - precision: 0.8847 - accuracy: 0.8755 - val_loss: 0.4393 - val_precision: 0.8696 - val_accuracy: 0.8300\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3509 - precision: 0.8919 - accuracy: 0.8800 - val_loss: 0.4067 - val_precision: 0.8657 - val_accuracy: 0.8420\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3417 - precision: 0.8915 - accuracy: 0.8815 - val_loss: 0.4078 - val_precision: 0.8745 - val_accuracy: 0.8390\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3377 - precision: 0.8938 - accuracy: 0.8802 - val_loss: 0.4115 - val_precision: 0.8624 - val_accuracy: 0.8500\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3370 - precision: 0.8890 - accuracy: 0.8795 - val_loss: 0.3897 - val_precision: 0.8564 - val_accuracy: 0.8610\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3250 - precision: 0.8947 - accuracy: 0.8870 - val_loss: 0.4127 - val_precision: 0.8764 - val_accuracy: 0.8470\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3188 - precision: 0.9056 - accuracy: 0.8907 - val_loss: 0.3997 - val_precision: 0.8805 - val_accuracy: 0.8530\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3216 - precision: 0.8982 - accuracy: 0.8885 - val_loss: 0.3911 - val_precision: 0.8763 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe7d0319c10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10 = init_model()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model_10.fit(X_train_10, y_train_10, \n",
    "          epochs=500, \n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.641958041958042"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_test_y_10.sum()/len(apple_test_y_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9718 - precision: 0.6716 - accuracy: 0.5846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9718372821807861, 0.6716101765632629, 0.5846154093742371]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.evaluate(apple_test_x_10, apple_test_y_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 5 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_train_x_5, apple_train_y_5 = build_arrays(train_df,input_cols=INPUT_COLS, target_col='5D_return_bin', time_window=40, stride=1)\n",
    "apple_test_x_5, apple_test_y_5 = build_arrays(test_df,input_cols=INPUT_COLS, target_col='5D_return_bin', time_window=40, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train_5 =  apple_train_x_5[[sample_indx], :][0]\n",
    "y_train_5 = apple_train_y_5[[sample_indx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 2.7442 - precision: 0.5604 - accuracy: 0.5322 - val_loss: 2.3977 - val_precision: 0.5335 - val_accuracy: 0.5380\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 2.1086 - precision: 0.5546 - accuracy: 0.5543 - val_loss: 1.8472 - val_precision: 0.5552 - val_accuracy: 0.5680\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6319 - precision: 0.5630 - accuracy: 0.5620 - val_loss: 1.4419 - val_precision: 0.5654 - val_accuracy: 0.5700\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.2819 - precision: 0.5783 - accuracy: 0.5730 - val_loss: 1.1451 - val_precision: 0.5769 - val_accuracy: 0.5780\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.0393 - precision: 0.5957 - accuracy: 0.5835 - val_loss: 0.9486 - val_precision: 0.5898 - val_accuracy: 0.5800\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.8794 - precision: 0.5977 - accuracy: 0.5878 - val_loss: 0.8330 - val_precision: 0.5815 - val_accuracy: 0.5920\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.7938 - precision: 0.6005 - accuracy: 0.5925 - val_loss: 0.7714 - val_precision: 0.6070 - val_accuracy: 0.6020\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.7508 - precision: 0.6081 - accuracy: 0.5932 - val_loss: 0.7402 - val_precision: 0.5832 - val_accuracy: 0.5870\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.7262 - precision: 0.6121 - accuracy: 0.6010 - val_loss: 0.7208 - val_precision: 0.6055 - val_accuracy: 0.6040\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.7109 - precision: 0.6213 - accuracy: 0.6108 - val_loss: 0.7156 - val_precision: 0.5819 - val_accuracy: 0.5720\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6993 - precision: 0.6201 - accuracy: 0.6095 - val_loss: 0.7034 - val_precision: 0.5924 - val_accuracy: 0.5950\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6881 - precision: 0.6354 - accuracy: 0.6270 - val_loss: 0.6969 - val_precision: 0.6059 - val_accuracy: 0.6110\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6800 - precision: 0.6374 - accuracy: 0.6325 - val_loss: 0.6884 - val_precision: 0.6202 - val_accuracy: 0.6240\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6759 - precision: 0.6413 - accuracy: 0.6365 - val_loss: 0.6828 - val_precision: 0.6200 - val_accuracy: 0.6300\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6716 - precision: 0.6495 - accuracy: 0.6415 - val_loss: 0.6740 - val_precision: 0.6242 - val_accuracy: 0.6380\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6656 - precision: 0.6478 - accuracy: 0.6495 - val_loss: 0.6785 - val_precision: 0.6347 - val_accuracy: 0.6400\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.6592 - precision: 0.6565 - accuracy: 0.6507 - val_loss: 0.6797 - val_precision: 0.6138 - val_accuracy: 0.6090\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.6543 - precision: 0.6553 - accuracy: 0.6543 - val_loss: 0.6788 - val_precision: 0.6181 - val_accuracy: 0.6330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe47d764310>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = init_model()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model_5.fit(X_train_5, y_train_5, \n",
    "          epochs=500, \n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111888111888112"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_test_y_5.sum()/len(apple_test_y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7412 - precision: 0.6319 - accuracy: 0.5483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7412089705467224, 0.6319444179534912, 0.548251748085022]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(apple_test_x_5, apple_test_y_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for 20 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import expand_dims\n",
    "X_train_cnn_20 = expand_dims(X_train_20, axis=-1)\n",
    "X_test_cnn_20 = expand_dims(apple_test_x_20, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_cnn():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(40, 15, 1)))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(60, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6852 - accuracy: 0.5670 - val_loss: 0.6656 - val_accuracy: 0.5830\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5767 - val_loss: 0.6574 - val_accuracy: 0.5900\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6487 - accuracy: 0.6097 - val_loss: 0.6172 - val_accuracy: 0.6400\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.6495 - val_loss: 0.5857 - val_accuracy: 0.6950\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5692 - accuracy: 0.6965 - val_loss: 0.5227 - val_accuracy: 0.7250\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.7655 - val_loss: 0.5045 - val_accuracy: 0.7340\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.7950 - val_loss: 0.4304 - val_accuracy: 0.8150\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3822 - accuracy: 0.8395 - val_loss: 0.4086 - val_accuracy: 0.8120\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8643 - val_loss: 0.4091 - val_accuracy: 0.8280\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.8903 - val_loss: 0.3639 - val_accuracy: 0.8510\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2457 - accuracy: 0.8995 - val_loss: 0.3718 - val_accuracy: 0.8520\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2234 - accuracy: 0.9118 - val_loss: 0.2886 - val_accuracy: 0.8900\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1832 - accuracy: 0.9255 - val_loss: 0.3018 - val_accuracy: 0.8940\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1912 - accuracy: 0.9255 - val_loss: 0.2794 - val_accuracy: 0.8970\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1557 - accuracy: 0.9375 - val_loss: 0.2736 - val_accuracy: 0.8970\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1440 - accuracy: 0.9425 - val_loss: 0.3069 - val_accuracy: 0.8910\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9482 - val_loss: 0.3080 - val_accuracy: 0.8940\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1166 - accuracy: 0.9557 - val_loss: 0.3533 - val_accuracy: 0.8850\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.9548 - val_loss: 0.3121 - val_accuracy: 0.9000\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.9585 - val_loss: 0.3413 - val_accuracy: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f540df12c90>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_20 = initialize_model_cnn()\n",
    "\n",
    "model_cnn_20.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_cnn_20.fit(X_train_cnn_20, y_train_20, \n",
    "          epochs=500, \n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 5.2828 - accuracy: 0.4364 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.282845497131348, 0.4363636374473572]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_20.evaluate(X_test_cnn_20, apple_test_y_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for 10 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn_10 = expand_dims(X_train_10, axis=-1)\n",
    "X_test_cnn_10 = expand_dims(apple_test_x_10, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.5315 - val_loss: 0.6884 - val_accuracy: 0.5670\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6887 - accuracy: 0.5540 - val_loss: 0.6843 - val_accuracy: 0.5640\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5497 - val_loss: 0.6807 - val_accuracy: 0.5780\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6793 - accuracy: 0.5675 - val_loss: 0.6742 - val_accuracy: 0.5850\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6687 - accuracy: 0.5817 - val_loss: 0.6578 - val_accuracy: 0.6150\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6202 - val_loss: 0.6360 - val_accuracy: 0.6080\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6284 - accuracy: 0.6388 - val_loss: 0.6216 - val_accuracy: 0.6560\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6039 - accuracy: 0.6727 - val_loss: 0.5843 - val_accuracy: 0.6850\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.7207 - val_loss: 0.5567 - val_accuracy: 0.7260\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5000 - accuracy: 0.7705 - val_loss: 0.5579 - val_accuracy: 0.7190\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.8055 - val_loss: 0.5065 - val_accuracy: 0.7570\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3780 - accuracy: 0.8357 - val_loss: 0.4284 - val_accuracy: 0.8040\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8737 - val_loss: 0.3946 - val_accuracy: 0.8270\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.8975 - val_loss: 0.4167 - val_accuracy: 0.8340\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2487 - accuracy: 0.9003 - val_loss: 0.3817 - val_accuracy: 0.8470\n",
      "Epoch 16/500\n",
      " 37/250 [===>..........................] - ETA: 0s - loss: 0.1800 - accuracy: 0.9291"
     ]
    }
   ],
   "source": [
    "model_cnn_10 = initialize_model_cnn()\n",
    "\n",
    "model_cnn_10.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_cnn_10.fit(X_train_cnn_10, y_train_10, \n",
    "          epochs=500, \n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 2.3879 - accuracy: 0.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.38793683052063, 0.5064747929573059]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_10.evaluate(X_test_cnn_10, apple_test_y_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for 5 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn_5 = expand_dims(X_train_5, axis=-1)\n",
    "X_test_cnn_5 = expand_dims(apple_test_x_5, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5217 - val_loss: 0.6860 - val_accuracy: 0.5590\n",
      "Epoch 2/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5315 - val_loss: 0.6900 - val_accuracy: 0.5590\n",
      "Epoch 3/500\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5430 - val_loss: 0.6845 - val_accuracy: 0.5660\n",
      "Epoch 4/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5397 - val_loss: 0.6930 - val_accuracy: 0.5280\n",
      "Epoch 5/500\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5433 - val_loss: 0.6833 - val_accuracy: 0.5600\n",
      "Epoch 6/500\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5355 - val_loss: 0.6809 - val_accuracy: 0.5640\n",
      "Epoch 7/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5562 - val_loss: 0.6740 - val_accuracy: 0.5990\n",
      "Epoch 8/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.5738 - val_loss: 0.6710 - val_accuracy: 0.5950\n",
      "Epoch 9/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6003 - val_loss: 0.6499 - val_accuracy: 0.6130\n",
      "Epoch 10/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6273 - val_loss: 0.6386 - val_accuracy: 0.6210\n",
      "Epoch 11/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6622 - val_loss: 0.6169 - val_accuracy: 0.6440\n",
      "Epoch 12/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6905 - val_loss: 0.5985 - val_accuracy: 0.6790\n",
      "Epoch 13/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7230 - val_loss: 0.5933 - val_accuracy: 0.6880\n",
      "Epoch 14/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7540 - val_loss: 0.5846 - val_accuracy: 0.6960\n",
      "Epoch 15/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7815 - val_loss: 0.5836 - val_accuracy: 0.7100\n",
      "Epoch 16/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8070 - val_loss: 0.5822 - val_accuracy: 0.7210\n",
      "Epoch 17/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8330 - val_loss: 0.5959 - val_accuracy: 0.7330\n",
      "Epoch 18/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8505 - val_loss: 0.5752 - val_accuracy: 0.7410\n",
      "Epoch 19/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8880 - val_loss: 0.6676 - val_accuracy: 0.7450\n",
      "Epoch 20/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8888 - val_loss: 0.7319 - val_accuracy: 0.7200\n",
      "Epoch 21/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9035 - val_loss: 0.6903 - val_accuracy: 0.7590\n",
      "Epoch 22/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9252 - val_loss: 0.8215 - val_accuracy: 0.7620\n",
      "Epoch 23/500\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9252 - val_loss: 0.8866 - val_accuracy: 0.7570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5409b5ab90>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_5 = initialize_model_cnn()\n",
    "\n",
    "model_cnn_5.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_cnn_5.fit(X_train_cnn_5, y_train_5, \n",
    "          epochs=500, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 1.0793 - accuracy: 0.4662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0792920589447021, 0.466187059879303]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_5.evaluate(X_test_cnn_5, apple_test_y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
