{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlchartist.array_builder import full_dataset_randomised_arrays\n",
    "from mlchartist.preprocessing import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df 19103\n",
      "\n",
      "trains 16850\n",
      "tests 2253\n"
     ]
    }
   ],
   "source": [
    "apple = pd.read_csv('../raw_data/processed/aapl.csv')\n",
    "google = pd.read_csv('../raw_data/processed/googl.csv')\n",
    "amzn = pd.read_csv('../raw_data/processed/amzn.csv')\n",
    "\n",
    "joined_df = pd.DataFrame()\n",
    "joined_df = joined_df.append(apple)\n",
    "joined_df = joined_df.append(google)\n",
    "joined_df = joined_df.append(amzn)\n",
    "\n",
    "print('joined_df', len(joined_df))\n",
    "print('')\n",
    "\n",
    "\n",
    "apple_train, apple_test = train_test_split(apple, '3Y')\n",
    "google_train, google_test = train_test_split(google, '3Y')\n",
    "amazon_train, amazon_test = train_test_split(amzn, '3Y')\n",
    "\n",
    "print('trains', len(apple_train) + len(google_train) + len(amazon_train))\n",
    "print('tests', len(apple_test) + len(google_test) + len(amazon_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\mlchartist\\preprocessing.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.to_datetime(df['date'], format=('%Y-%m-%d'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Companies in Dataset\n",
      "Starting AAPL: Company 1 of 3\n",
      "Starting GOOGL: Company 2 of 3\n",
      "Starting AMZN: Company 3 of 3\n",
      "All Companies Completed\n",
      "\n",
      "Processing Stats: {'AAPL': {'train_possible_windows': 167.28, 'train_outliers': 0, 'train_windows': 168, 'test_possible_windows': 15.02, 'test_outliers': 1, 'test_windows': 15}, 'GOOGL': {'train_possible_windows': 66.66, 'train_outliers': 0, 'train_windows': 67, 'test_possible_windows': 15.02, 'test_outliers': 1, 'test_windows': 15}, 'AMZN': {'train_possible_windows': 103.06, 'train_outliers': 1, 'train_windows': 103, 'test_possible_windows': 15.02, 'test_outliers': 1, 'test_windows': 15}}\n",
      "\n",
      "\n",
      "### Stats ###\n",
      "train_x (338, 6, 15)\n",
      "train_y (338, 6, 3)\n",
      "test_x (45, 6, 15)\n",
      "test_y (45, 6, 3)\n",
      "scaler RobustScaler()\n",
      "\n",
      "\n",
      "### Validation ###\n",
      "apple_train 167.28\n",
      "apple_test 15.02\n",
      "google_train 66.66\n",
      "google_test 15.02\n",
      "amazon_train 103.06\n",
      "amazon_test 15.02\n",
      "all trains sets 337.0\n",
      "all tests sets 45.06\n"
     ]
    }
   ],
   "source": [
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "              'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "TARGET_COLS=['5TD_return', '10TD_return', '20TD_return']\n",
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "\n",
    "stride = 80\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y, scaler = full_dataset_randomised_arrays(joined_df, \n",
    "                                                                                stride=stride, \n",
    "                                                                                input_cols=INPUT_COLS, \n",
    "                                                                                outlier_threshold=1, \n",
    "                                                                                outlier_validation=outlier_validation, \n",
    "                                                                                check_train_outliers=True,\n",
    "                                                                                check_test_outliers=True, \n",
    "                                                                                target_col=TARGET_COLS, \n",
    "                                                                                time_window=6,\n",
    "                                                                                test_set_size='3Y')\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('train_x', train_x.shape)\n",
    "print('train_y', train_y.shape)\n",
    "print('test_x', test_x.shape)\n",
    "print('test_y', test_y.shape)\n",
    "print('scaler', scaler)\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Validation ###')\n",
    "print('apple_train', len(apple_train)/stride)\n",
    "print('apple_test', len(apple_test)/stride)\n",
    "print('google_train', len(google_train)/stride)\n",
    "print('google_test', len(google_test)/stride)\n",
    "print('amazon_train', len(amazon_train)/stride)\n",
    "print('amazon_test', len(amazon_test)/stride)\n",
    "\n",
    "print('all trains sets', (len(apple_train) + len(google_train) + len(amazon_train))/stride)\n",
    "print('all tests sets', (len(apple_test) + len(google_test) + len(amazon_test))/stride)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlchartist.preprocessing import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def full_dataset_randomised_arrays_FIXED(df, \n",
    "                                         test_set_size='3Y', \n",
    "                                         time_window=5, \n",
    "                                         stride=3, \n",
    "                                         check_train_outliers=False, \n",
    "                                         check_test_outliers=False, \n",
    "                                         outlier_threshold=1, \n",
    "                                         input_cols=['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', \n",
    "                                                     'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff', 'MACD_signal', '1D_past_return', \n",
    "                                                     '5D_past_return', '10D_past_return'], \n",
    "                                         target_col=['1D_past_return', '5D_past_return', '10D_past_return'], \n",
    "                                         outlier_validation={'ATR': [-100, 100], 'Stochastic': [0, 100], \n",
    "                                                             'Stochastic_signal': [-10, 110], '5D_past_return': [-0.5, 0.5]}):\n",
    "    \"\"\"\n",
    "    A function to transform dataframe into input and output arrays.\n",
    "\n",
    "    Takes:\n",
    "    df - input dataframe\n",
    "    time_window (default=5) - time series length\n",
    "    stride (default=3) - controls the number of windows taken (i.e. max_num_windows = len(df)/strides)\n",
    "    check_outliers (default=False) - controls whether it checks each window for outliers or not\n",
    "    input_cols (default = 'RSI', 'Stochastic', 'Stochastic_signal', 'ADI',\n",
    "       'OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "       'MACD_signal', '1D_past_return', '5D_past_return', '10D_past_return']) - all input features, that should \n",
    "       be included in the input array target_col (default = '5TD_return') - target variable, first \n",
    "       (newest) value for each input array\n",
    "    target_col - all columns that should be included in target_col\n",
    "        (default: target_col=['1D_past_return', '5D_past_return', '10D_past_return'])\n",
    "    outlier_validation - a dict that sets the outlier checks to be completed. Enter data in the format:\n",
    "        outlier_validation={'column_name': [lower_threshold, upper_threshold]} \n",
    "        Example: {'Stochastic': [0, 100], 'Stochastic_signal': [-10, 110], '5D_past_return': [-0.5, 0.5]}\n",
    "\n",
    "    Return tuple (input_array, target_array).\n",
    "\n",
    "    input_array dim: (number_of_samples x time_window x features_number)\n",
    "    target_array dim: (number_of_samples x time_window x returns_numbder)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## split into train/test split\n",
    "    raw_train_set = pd.DataFrame()\n",
    "    raw_test_set = pd.DataFrame()\n",
    "    for ticker in df['ticker'].unique():\n",
    "        company_df = df[df['ticker'] == ticker]\n",
    "        temp_train_set, temp_test_set = train_test_split(company_df, test_set_size)\n",
    "        raw_train_set = raw_train_set.append(temp_train_set)\n",
    "        raw_test_set = raw_test_set.append(temp_test_set)\n",
    "        \n",
    "    ## create copy of train_set & fit scaler\n",
    "    no_outlier_train_df = raw_train_set.copy()\n",
    "    for k, v in outlier_validation.items(): \n",
    "        no_outlier_train_df = no_outlier_train_df[no_outlier_train_df[k].between(v[0], v[1])]\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(no_outlier_train_df[input_cols])\n",
    "    \n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    stats2 = []\n",
    "    stats = {}\n",
    "    ## go company by company\n",
    "    print(f\"{df['ticker'].unique().size} Companies in Dataset\")\n",
    "    status_count = 0\n",
    "    for ticker in df['ticker'].unique():\n",
    "        status_count +=1\n",
    "        stats[ticker] = {}\n",
    "        print(f\"Starting {ticker}: Company {status_count} of {df['ticker'].unique().size}\")\n",
    "        train_outlier_count = 0\n",
    "        test_outlier_count = 0\n",
    "        company_train_x_array = []\n",
    "        company_train_y_array = []\n",
    "        \n",
    "        company_test_x_array = []\n",
    "        company_test_y_array = []\n",
    "\n",
    "        ## train\n",
    "        company_train_df = raw_train_set[raw_train_set['ticker'] == ticker]\n",
    "        company_train_sorted = company_train_df.sort_values('date', ascending=False)\n",
    "        company_train_sorted.reset_index(drop=True, inplace=True)\n",
    "        for row in range(0, len(company_train_sorted), stride):\n",
    "            outlier = False\n",
    "            df_slice = company_train_sorted.iloc[row: row + time_window].copy()\n",
    "            ## check for outliers\n",
    "            if check_train_outliers == True:\n",
    "                for k, v in outlier_validation.items(): \n",
    "                    if ((df_slice[k] < v[0]).any() == True) or ((df_slice[k] > v[1]).any() == True): outlier = True\n",
    "                \n",
    "            if df_slice.shape[0]==time_window and outlier==False:\n",
    "                ## scale the window\n",
    "                df_slice.loc[:, input_cols] = scaler.transform(df_slice[input_cols])\n",
    "                ## add to company array\n",
    "                company_train_x_array.append(np.array(df_slice[input_cols].values))\n",
    "                company_train_y_array.append(np.array(df_slice[target_col].iloc[0]))\n",
    "            else: train_outlier_count+=1\n",
    "        \n",
    "        if train_outlier_count/(len(company_train_sorted)/stride) <= outlier_threshold:\n",
    "            stats[ticker]['train_possible_windows'] = (len(company_train_sorted)/stride)\n",
    "            stats[ticker]['train_outliers'] = train_outlier_count\n",
    "            stats[ticker]['train_windows'] = len(company_train_x_array)\n",
    "            train_x.extend(company_train_x_array)\n",
    "            train_y.extend(company_train_y_array)\n",
    "            \n",
    "\n",
    "        ## test\n",
    "        company_test_df = raw_test_set[raw_test_set['ticker'] == ticker]\n",
    "        company_test_sorted = company_test_df.sort_values('date', ascending=False)\n",
    "        company_test_sorted.reset_index(drop=True, inplace=True)\n",
    "        for row in range(0, len(company_test_sorted), stride):\n",
    "            outlier = False\n",
    "            df_slice = company_test_sorted.iloc[row: row + time_window].copy()\n",
    "            ## check for outliers\n",
    "            if check_test_outliers == True:\n",
    "                for k, v in outlier_validation.items(): \n",
    "                    if ((df_slice[k] < v[0]).any() == True) or ((df_slice[k] > v[1]).any() == True): outlier = True\n",
    "                \n",
    "            if df_slice.shape[0]==time_window and outlier==False:\n",
    "                ## scale the window\n",
    "                df_slice.loc[:, input_cols] = scaler.transform(df_slice[input_cols])\n",
    "                ## add to company array\n",
    "                company_test_x_array.append(np.array(df_slice[input_cols].values))\n",
    "                company_test_y_array.append(np.array(df_slice[target_col].iloc[0]))\n",
    "            else: test_outlier_count+=1\n",
    "        \n",
    "        if train_outlier_count/(len(company_train_sorted)/stride) <= outlier_threshold:\n",
    "            stats[ticker]['test_possible_windows'] = (len(company_test_sorted)/stride)\n",
    "            stats[ticker]['test_outliers'] = test_outlier_count\n",
    "            stats[ticker]['test_windows'] = len(company_test_x_array)\n",
    "            test_x.extend(company_test_x_array)\n",
    "            test_y.extend(company_test_y_array)\n",
    "    \n",
    "    print('All Companies Completed')\n",
    "    print('')\n",
    "    print('Processing Stats:', stats)\n",
    "    \n",
    "    ## shuffle arrays\n",
    "    output_train_x = []\n",
    "    output_train_y = []\n",
    "    index_list = random.sample(range(len(train_x)), len(train_x))\n",
    "    for i in index_list:\n",
    "        output_train_x.append(train_x[i])\n",
    "        output_train_y.append(train_y[i])\n",
    "    return np.array(output_train_x), np.array(output_train_y), np.array(test_x), np.array(test_y), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 83, 66, 87, 39]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(range(100), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(range(0, 10))\n",
    "random.choice(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\.venvs\\lewagon\\lib\\site-packages\\mlchartist\\preprocessing.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.to_datetime(df['date'], format=('%Y-%m-%d'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Companies in Dataset\n",
      "Starting AAPL: Company 1 of 3\n",
      "Starting GOOGL: Company 2 of 3\n",
      "Starting AMZN: Company 3 of 3\n",
      "All Companies Completed\n",
      "\n",
      "Processing Stats: {'AAPL': {'train_possible_windows': 83.64, 'train_outliers': 0, 'train_windows': 84, 'test_possible_windows': 7.51, 'test_outliers': 0, 'test_windows': 8}, 'GOOGL': {'train_possible_windows': 33.33, 'train_outliers': 0, 'train_windows': 34, 'test_possible_windows': 7.51, 'test_outliers': 0, 'test_windows': 8}, 'AMZN': {'train_possible_windows': 51.53, 'train_outliers': 0, 'train_windows': 52, 'test_possible_windows': 7.51, 'test_outliers': 0, 'test_windows': 8}}\n",
      "len(train_x) 170\n",
      "index_list [151, 111, 55, 92, 70, 120, 41, 131, 113, 13, 91, 57, 37, 30, 71, 136, 123, 22, 14, 154, 11, 119, 61, 62, 5, 26, 46, 168, 98, 38, 77, 7, 84, 122, 158, 68, 112, 21, 23, 54, 49, 33, 94, 85, 66, 9, 142, 141, 15, 74, 130, 82, 104, 137, 48, 109, 27, 95, 20, 16, 1, 44, 162, 51, 139, 166, 116, 34, 110, 0, 42, 4, 125, 133, 107, 102, 150, 75, 24, 134, 101, 19, 59, 105, 63, 40, 10, 29, 39, 83, 146, 99, 6, 45, 90, 148, 67, 35, 3, 87, 53, 28, 159, 89, 117, 132, 93, 52, 103, 169, 157, 76, 115, 50, 106, 165, 12, 81, 80, 56, 69, 145, 156, 118, 31, 149, 47, 79, 65, 73, 96, 143, 60, 86, 129, 25, 147, 78, 97, 43, 124, 100, 36, 8, 160, 58, 153, 135, 144, 114, 18, 17, 167, 32, 164, 155, 128, 2, 121, 140, 163, 161, 126, 88, 72, 138, 108, 64, 152, 127]\n",
      "len(output_train_x) 170\n",
      "\n",
      "\n",
      "### Stats ###\n",
      "train_x (170, 6, 15)\n",
      "train_y (170, 3)\n",
      "test_x (24, 6, 15)\n",
      "test_y (24, 3)\n",
      "scaler RobustScaler()\n",
      "\n",
      "\n",
      "### Validation ###\n",
      "apple_train 83.64\n",
      "apple_test 7.51\n",
      "google_train 33.33\n",
      "google_test 7.51\n",
      "amazon_train 51.53\n",
      "amazon_test 7.51\n",
      "all trains sets 168.5\n",
      "all tests sets 22.53\n"
     ]
    }
   ],
   "source": [
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff',\n",
    "              'MACD_signal', '5TD_return', '10TD_return', '20TD_return']\n",
    "TARGET_COLS=['5TD_return', '10TD_return', '20TD_return']\n",
    "outlier_validation={'5TD_return': [-0.5, 0.5]}\n",
    "\n",
    "stride = 100\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y, scaler = full_dataset_randomised_arrays_FIXED(joined_df, \n",
    "                                                                                stride=stride, \n",
    "                                                                                input_cols=INPUT_COLS, \n",
    "                                                                                outlier_threshold=1, \n",
    "                                                                                outlier_validation=outlier_validation, \n",
    "                                                                                check_train_outliers=True,\n",
    "                                                                                check_test_outliers=True, \n",
    "                                                                                target_col=TARGET_COLS, \n",
    "                                                                                time_window=6,\n",
    "                                                                                test_set_size='3Y')\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Stats ###')\n",
    "print('train_x', train_x.shape)\n",
    "print('train_y', train_y.shape)\n",
    "print('test_x', test_x.shape)\n",
    "print('test_y', test_y.shape)\n",
    "print('scaler', scaler)\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('### Validation ###')\n",
    "print('apple_train', len(apple_train)/stride)\n",
    "print('apple_test', len(apple_test)/stride)\n",
    "print('google_train', len(google_train)/stride)\n",
    "print('google_test', len(google_test)/stride)\n",
    "print('amazon_train', len(amazon_train)/stride)\n",
    "print('amazon_test', len(amazon_test)/stride)\n",
    "\n",
    "print('all trains sets', (len(apple_train) + len(google_train) + len(amazon_train))/stride)\n",
    "print('all tests sets', (len(apple_test) + len(google_test) + len(amazon_test))/stride)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13040668, -0.07898534, -0.03820554])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
