{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from mlchartist.array_builder import build_arrays\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/processed/amd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIVE_TR = 0.0006\n",
    "TEN_TR = 0.0012\n",
    "TWENTY_TR = 0.0024\n",
    "INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal', 'ADI','OBV', 'ATR', 'ADX', 'ADX_pos', 'ADX_neg', 'MACD', 'MACD_diff','MACD_signal', '1D_past_return', '5D_past_return', '10D_past_return']\n",
    "#INPUT_COLS = ['RSI', 'Stochastic', 'Stochastic_signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['5D_return_bin'] = (df['5TD_return'] >= FIVE_TR)\n",
    "df['10D_return_bin'] = (df['10TD_return'] >= TEN_TR)\n",
    "df['20D_return_bin'] = (df['20TD_return'] >= TWENTY_TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['date'].dt.year >= 2018]\n",
    "train_df = df[df['date'].dt.year < 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(train_df[INPUT_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "train_df.loc[:, INPUT_COLS] = scaler.transform(train_df[INPUT_COLS])\n",
    "test_df.loc[:, INPUT_COLS] = scaler.transform(test_df[INPUT_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stochastic</th>\n",
       "      <th>Stochastic_signal</th>\n",
       "      <th>ADI</th>\n",
       "      <th>OBV</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADX_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>5TD_return</th>\n",
       "      <th>10TD_return</th>\n",
       "      <th>20TD_return</th>\n",
       "      <th>1D_past_return</th>\n",
       "      <th>5D_past_return</th>\n",
       "      <th>10D_past_return</th>\n",
       "      <th>5D_return_bin</th>\n",
       "      <th>10D_return_bin</th>\n",
       "      <th>20D_return_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>1983-05-06</td>\n",
       "      <td>2.017312</td>\n",
       "      <td>1.481129</td>\n",
       "      <td>1.623227</td>\n",
       "      <td>0.392659</td>\n",
       "      <td>-1.085295</td>\n",
       "      <td>-0.255501</td>\n",
       "      <td>-0.165659</td>\n",
       "      <td>3.052217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513197</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.187446</td>\n",
       "      <td>1.182040</td>\n",
       "      <td>2.366785</td>\n",
       "      <td>1.889872</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>1983-05-09</td>\n",
       "      <td>1.775631</td>\n",
       "      <td>1.294889</td>\n",
       "      <td>1.523539</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>-1.086478</td>\n",
       "      <td>-0.271501</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>2.740693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058355</td>\n",
       "      <td>0.168877</td>\n",
       "      <td>-0.386362</td>\n",
       "      <td>2.348057</td>\n",
       "      <td>2.163525</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>1983-05-10</td>\n",
       "      <td>1.845256</td>\n",
       "      <td>1.446209</td>\n",
       "      <td>1.503475</td>\n",
       "      <td>0.394434</td>\n",
       "      <td>-1.085177</td>\n",
       "      <td>-0.314792</td>\n",
       "      <td>0.231528</td>\n",
       "      <td>2.734199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708618</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>0.101399</td>\n",
       "      <td>0.152972</td>\n",
       "      <td>0.284007</td>\n",
       "      <td>1.832815</td>\n",
       "      <td>1.661055</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>1983-05-11</td>\n",
       "      <td>1.594612</td>\n",
       "      <td>1.259969</td>\n",
       "      <td>1.424710</td>\n",
       "      <td>0.394046</td>\n",
       "      <td>-1.085729</td>\n",
       "      <td>-0.345513</td>\n",
       "      <td>0.392181</td>\n",
       "      <td>2.537508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795959</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.161348</td>\n",
       "      <td>0.161348</td>\n",
       "      <td>-0.387326</td>\n",
       "      <td>0.855950</td>\n",
       "      <td>1.585374</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>1983-05-12</td>\n",
       "      <td>1.137584</td>\n",
       "      <td>0.899128</td>\n",
       "      <td>1.283763</td>\n",
       "      <td>0.393717</td>\n",
       "      <td>-1.086314</td>\n",
       "      <td>-0.340867</td>\n",
       "      <td>0.429069</td>\n",
       "      <td>2.140540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861299</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>0.139471</td>\n",
       "      <td>0.190520</td>\n",
       "      <td>-0.742914</td>\n",
       "      <td>-0.043127</td>\n",
       "      <td>1.388111</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>-0.378039</td>\n",
       "      <td>0.193930</td>\n",
       "      <td>0.835716</td>\n",
       "      <td>-2.377210</td>\n",
       "      <td>3.718731</td>\n",
       "      <td>-0.263589</td>\n",
       "      <td>-0.319852</td>\n",
       "      <td>-0.246561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559063</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.122507</td>\n",
       "      <td>0.207028</td>\n",
       "      <td>-0.889815</td>\n",
       "      <td>0.227926</td>\n",
       "      <td>0.438127</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8733</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>-0.464275</td>\n",
       "      <td>0.030610</td>\n",
       "      <td>0.428244</td>\n",
       "      <td>-2.377082</td>\n",
       "      <td>3.688823</td>\n",
       "      <td>-0.290227</td>\n",
       "      <td>-0.367418</td>\n",
       "      <td>-0.351216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510528</td>\n",
       "      <td>0.104207</td>\n",
       "      <td>0.143403</td>\n",
       "      <td>0.186424</td>\n",
       "      <td>-0.193981</td>\n",
       "      <td>-0.593503</td>\n",
       "      <td>0.178172</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8734</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>-0.351866</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>0.078404</td>\n",
       "      <td>-2.385162</td>\n",
       "      <td>3.722314</td>\n",
       "      <td>-0.299008</td>\n",
       "      <td>-0.456620</td>\n",
       "      <td>-0.167978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468329</td>\n",
       "      <td>0.150997</td>\n",
       "      <td>0.152896</td>\n",
       "      <td>0.229820</td>\n",
       "      <td>0.157486</td>\n",
       "      <td>-0.483774</td>\n",
       "      <td>0.455567</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8735</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>-0.318476</td>\n",
       "      <td>0.045852</td>\n",
       "      <td>0.025668</td>\n",
       "      <td>-2.381179</td>\n",
       "      <td>3.749501</td>\n",
       "      <td>-0.327697</td>\n",
       "      <td>-0.539451</td>\n",
       "      <td>-0.267163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430682</td>\n",
       "      <td>0.126066</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.262559</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>-0.498246</td>\n",
       "      <td>0.291978</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8736</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>-0.683396</td>\n",
       "      <td>-0.623493</td>\n",
       "      <td>-0.207285</td>\n",
       "      <td>-2.418575</td>\n",
       "      <td>3.710514</td>\n",
       "      <td>-0.338541</td>\n",
       "      <td>-0.578338</td>\n",
       "      <td>-0.409622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404582</td>\n",
       "      <td>0.194553</td>\n",
       "      <td>0.158560</td>\n",
       "      <td>0.251946</td>\n",
       "      <td>-0.693122</td>\n",
       "      <td>-0.694096</td>\n",
       "      <td>0.066614</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8737 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker       date       RSI  Stochastic  Stochastic_signal       ADI  \\\n",
       "0       AMD 1983-05-06  2.017312    1.481129           1.623227  0.392659   \n",
       "1       AMD 1983-05-09  1.775631    1.294889           1.523539  0.393100   \n",
       "2       AMD 1983-05-10  1.845256    1.446209           1.503475  0.394434   \n",
       "3       AMD 1983-05-11  1.594612    1.259969           1.424710  0.394046   \n",
       "4       AMD 1983-05-12  1.137584    0.899128           1.283763  0.393717   \n",
       "...     ...        ...       ...         ...                ...       ...   \n",
       "8732    AMD 2017-12-22 -0.378039    0.193930           0.835716 -2.377210   \n",
       "8733    AMD 2017-12-26 -0.464275    0.030610           0.428244 -2.377082   \n",
       "8734    AMD 2017-12-27 -0.351866   -0.003729           0.078404 -2.385162   \n",
       "8735    AMD 2017-12-28 -0.318476    0.045852           0.025668 -2.381179   \n",
       "8736    AMD 2017-12-29 -0.683396   -0.623493          -0.207285 -2.418575   \n",
       "\n",
       "           OBV       ATR       ADX   ADX_pos  ...  MACD_signal  5TD_return  \\\n",
       "0    -1.085295 -0.255501 -0.165659  3.052217  ...     0.513197    0.005231   \n",
       "1    -1.086478 -0.271501  0.037625  2.740693  ...     0.610482    0.000000   \n",
       "2    -1.085177 -0.314792  0.231528  2.734199  ...     0.708618   -0.011364   \n",
       "3    -1.085729 -0.345513  0.392181  2.537508  ...     0.795959    0.006206   \n",
       "4    -1.086314 -0.340867  0.429069  2.140540  ...     0.861299    0.020055   \n",
       "...        ...       ...       ...       ...  ...          ...         ...   \n",
       "8732  3.718731 -0.263589 -0.319852 -0.246561  ...    -0.559063    0.042735   \n",
       "8733  3.688823 -0.290227 -0.367418 -0.351216  ...    -0.510528    0.104207   \n",
       "8734  3.722314 -0.299008 -0.456620 -0.167978  ...    -0.468329    0.150997   \n",
       "8735  3.749501 -0.327697 -0.539451 -0.267163  ...    -0.430682    0.126066   \n",
       "8736  3.710514 -0.338541 -0.578338 -0.409622  ...    -0.404582    0.194553   \n",
       "\n",
       "      10TD_return  20TD_return  1D_past_return  5D_past_return  \\\n",
       "0        0.024412     0.187446        1.182040        2.366785   \n",
       "1        0.058355     0.168877       -0.386362        2.348057   \n",
       "2        0.101399     0.152972        0.284007        1.832815   \n",
       "3        0.161348     0.161348       -0.387326        0.855950   \n",
       "4        0.139471     0.190520       -0.742914       -0.043127   \n",
       "...           ...          ...             ...             ...   \n",
       "8732     0.122507     0.207028       -0.889815        0.227926   \n",
       "8733     0.143403     0.186424       -0.193981       -0.593503   \n",
       "8734     0.152896     0.229820        0.157486       -0.483774   \n",
       "8735     0.139336     0.262559        0.031208       -0.498246   \n",
       "8736     0.158560     0.251946       -0.693122       -0.694096   \n",
       "\n",
       "      10D_past_return  5D_return_bin  10D_return_bin  20D_return_bin  \n",
       "0            1.889872           True            True            True  \n",
       "1            2.163525          False            True            True  \n",
       "2            1.661055          False            True            True  \n",
       "3            1.585374           True            True            True  \n",
       "4            1.388111           True            True            True  \n",
       "...               ...            ...             ...             ...  \n",
       "8732         0.438127           True            True            True  \n",
       "8733         0.178172           True            True            True  \n",
       "8734         0.455567           True            True            True  \n",
       "8735         0.291978           True            True            True  \n",
       "8736         0.066614           True            True            True  \n",
       "\n",
       "[8737 rows x 23 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_train_x_20, apple_train_y_20 = build_arrays(train_df,input_cols=INPUT_COLS, target_col='20D_return_bin', time_window=30, stride=1)\n",
    "apple_test_x_20, apple_test_y_20 = build_arrays(test_df,input_cols=INPUT_COLS, target_col='20D_return_bin', time_window=30, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = list(range(len(apple_train_x_20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8708"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indx = random.sample(indx, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_20 =  apple_train_x_20[[sample_indx], :][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_train_20 = apple_train_y_20[[sample_indx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers, models \n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "optim = RMSprop(learning_rate=0.0001)\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.LSTM(100, return_sequences=True, input_shape=(30,15), activation='tanh'))\n",
    "    model.add(layers.LSTM(100, activation='tanh'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 20 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6917 - accuracy: 0.5256 - val_loss: 0.6877 - val_accuracy: 0.5375\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6877 - accuracy: 0.5396 - val_loss: 0.6818 - val_accuracy: 0.5625\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6820 - accuracy: 0.5596 - val_loss: 0.6786 - val_accuracy: 0.5617\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6782 - accuracy: 0.5719 - val_loss: 0.6721 - val_accuracy: 0.5633\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6727 - accuracy: 0.5888 - val_loss: 0.6669 - val_accuracy: 0.5725\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6688 - accuracy: 0.5844 - val_loss: 0.6608 - val_accuracy: 0.5742\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6618 - accuracy: 0.5958 - val_loss: 0.6540 - val_accuracy: 0.5900\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6487 - accuracy: 0.6190 - val_loss: 0.6470 - val_accuracy: 0.6017\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6437 - accuracy: 0.6279 - val_loss: 0.6477 - val_accuracy: 0.6017\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6383 - accuracy: 0.6254 - val_loss: 0.6365 - val_accuracy: 0.6067\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6316 - accuracy: 0.6315 - val_loss: 0.6379 - val_accuracy: 0.6142\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6227 - accuracy: 0.6433 - val_loss: 0.6316 - val_accuracy: 0.6150\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.6471 - val_loss: 0.6235 - val_accuracy: 0.6308\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6071 - accuracy: 0.6521 - val_loss: 0.6235 - val_accuracy: 0.6483\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6039 - accuracy: 0.6504 - val_loss: 0.6061 - val_accuracy: 0.6425\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5959 - accuracy: 0.6602 - val_loss: 0.6177 - val_accuracy: 0.6417\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5929 - accuracy: 0.6621 - val_loss: 0.5987 - val_accuracy: 0.6617\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5867 - accuracy: 0.6721 - val_loss: 0.5976 - val_accuracy: 0.6708\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5792 - accuracy: 0.6773 - val_loss: 0.5933 - val_accuracy: 0.6717\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5769 - accuracy: 0.6723 - val_loss: 0.5889 - val_accuracy: 0.6758\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5654 - accuracy: 0.6844 - val_loss: 0.5891 - val_accuracy: 0.6767\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5592 - accuracy: 0.6875 - val_loss: 0.5742 - val_accuracy: 0.6858\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5527 - accuracy: 0.6929 - val_loss: 0.5626 - val_accuracy: 0.6892\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7102 - val_loss: 0.5624 - val_accuracy: 0.7025\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7090 - val_loss: 0.5642 - val_accuracy: 0.7150\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5256 - accuracy: 0.7163 - val_loss: 0.5574 - val_accuracy: 0.7108\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5251 - accuracy: 0.7202 - val_loss: 0.5690 - val_accuracy: 0.7075\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.7285 - val_loss: 0.5407 - val_accuracy: 0.7233\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7271 - val_loss: 0.5406 - val_accuracy: 0.7258\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5004 - accuracy: 0.7344 - val_loss: 0.5541 - val_accuracy: 0.7158\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4934 - accuracy: 0.7387 - val_loss: 0.5352 - val_accuracy: 0.7267\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4831 - accuracy: 0.7510 - val_loss: 0.5339 - val_accuracy: 0.7317\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4748 - accuracy: 0.7490 - val_loss: 0.5325 - val_accuracy: 0.7450\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.7571 - val_loss: 0.5204 - val_accuracy: 0.7492\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.7633 - val_loss: 0.5224 - val_accuracy: 0.7533\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4503 - accuracy: 0.7652 - val_loss: 0.5187 - val_accuracy: 0.7425\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4492 - accuracy: 0.7742 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4401 - accuracy: 0.7781 - val_loss: 0.5127 - val_accuracy: 0.7475\n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.7792 - val_loss: 0.4966 - val_accuracy: 0.7683\n",
      "Epoch 40/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.7871 - val_loss: 0.5067 - val_accuracy: 0.7558\n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.4216 - accuracy: 0.7923 - val_loss: 0.4851 - val_accuracy: 0.7792\n",
      "Epoch 42/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.7877 - val_loss: 0.4983 - val_accuracy: 0.7567\n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.7969 - val_loss: 0.4859 - val_accuracy: 0.7667\n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3953 - accuracy: 0.8017 - val_loss: 0.4802 - val_accuracy: 0.7775\n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3929 - accuracy: 0.8096 - val_loss: 0.4852 - val_accuracy: 0.7658\n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3782 - accuracy: 0.8135 - val_loss: 0.4709 - val_accuracy: 0.7725\n",
      "Epoch 47/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3797 - accuracy: 0.8108 - val_loss: 0.4713 - val_accuracy: 0.7850\n",
      "Epoch 48/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3707 - accuracy: 0.8183 - val_loss: 0.4534 - val_accuracy: 0.7942\n",
      "Epoch 49/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3616 - accuracy: 0.8233 - val_loss: 0.4516 - val_accuracy: 0.7975\n",
      "Epoch 50/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3570 - accuracy: 0.8277 - val_loss: 0.4602 - val_accuracy: 0.7933\n",
      "Epoch 51/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3517 - accuracy: 0.8313 - val_loss: 0.4516 - val_accuracy: 0.8000\n",
      "Epoch 52/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3494 - accuracy: 0.8371 - val_loss: 0.4840 - val_accuracy: 0.7975\n",
      "Epoch 53/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8440 - val_loss: 0.4949 - val_accuracy: 0.7917\n",
      "Epoch 54/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3300 - accuracy: 0.8496 - val_loss: 0.4523 - val_accuracy: 0.8042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f305a0b2650>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20 = init_model()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model_20.fit(X_train_20, y_train_20, \n",
    "          epochs=500, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_test_y_20.sum()/len(apple_test_y_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9536 - accuracy: 0.5762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9535578489303589, 0.5761772990226746]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20.evaluate(apple_test_x_20, apple_test_y_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 10 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_train_x_10, apple_train_y_10 = build_arrays(train_df,input_cols=INPUT_COLS, target_col='10D_return_bin', time_window=30, stride=1)\n",
    "apple_test_x_10, apple_test_y_10 = build_arrays(test_df,input_cols=INPUT_COLS, target_col='10D_return_bin', time_window=30, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train_10 =  apple_train_x_10[[sample_indx], :][0]\n",
    "y_train_10 = apple_train_y_10[[sample_indx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6982 - accuracy: 0.4994 - val_loss: 0.6908 - val_accuracy: 0.5242\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6911 - accuracy: 0.5312 - val_loss: 0.6867 - val_accuracy: 0.5383\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6882 - accuracy: 0.5467 - val_loss: 0.6834 - val_accuracy: 0.5575\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6852 - accuracy: 0.5558 - val_loss: 0.6827 - val_accuracy: 0.5492\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6845 - accuracy: 0.5602 - val_loss: 0.6795 - val_accuracy: 0.5633\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6814 - accuracy: 0.5667 - val_loss: 0.6792 - val_accuracy: 0.5625\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6805 - accuracy: 0.5679 - val_loss: 0.6754 - val_accuracy: 0.5850\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6767 - accuracy: 0.5750 - val_loss: 0.6732 - val_accuracy: 0.5792\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6754 - accuracy: 0.5827 - val_loss: 0.6737 - val_accuracy: 0.5675\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6749 - accuracy: 0.5825 - val_loss: 0.6731 - val_accuracy: 0.5792\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6688 - accuracy: 0.5921 - val_loss: 0.6713 - val_accuracy: 0.5850\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6687 - accuracy: 0.5913 - val_loss: 0.6693 - val_accuracy: 0.5842\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6678 - accuracy: 0.5948 - val_loss: 0.6696 - val_accuracy: 0.5808\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6590 - accuracy: 0.6067 - val_loss: 0.6680 - val_accuracy: 0.5808\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6596 - accuracy: 0.6081 - val_loss: 0.6697 - val_accuracy: 0.5650\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6536 - accuracy: 0.6160 - val_loss: 0.6623 - val_accuracy: 0.5867\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6529 - accuracy: 0.6169 - val_loss: 0.6622 - val_accuracy: 0.5783\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.6119 - val_loss: 0.6577 - val_accuracy: 0.5992\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6437 - accuracy: 0.6198 - val_loss: 0.6562 - val_accuracy: 0.6125\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6421 - accuracy: 0.6244 - val_loss: 0.6563 - val_accuracy: 0.6042\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6395 - accuracy: 0.6308 - val_loss: 0.6616 - val_accuracy: 0.6008\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6354 - accuracy: 0.6377 - val_loss: 0.6554 - val_accuracy: 0.6008\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6326 - accuracy: 0.6369 - val_loss: 0.6529 - val_accuracy: 0.6167\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6246 - accuracy: 0.6452 - val_loss: 0.6469 - val_accuracy: 0.6275\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6203 - accuracy: 0.6569 - val_loss: 0.6489 - val_accuracy: 0.6200\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6164 - accuracy: 0.6488 - val_loss: 0.6489 - val_accuracy: 0.6308\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6124 - accuracy: 0.6538 - val_loss: 0.6424 - val_accuracy: 0.6392\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6038 - accuracy: 0.6617 - val_loss: 0.6520 - val_accuracy: 0.6300\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6045 - accuracy: 0.6733 - val_loss: 0.6408 - val_accuracy: 0.6425\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5992 - accuracy: 0.6733 - val_loss: 0.6420 - val_accuracy: 0.6483\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5896 - accuracy: 0.6790 - val_loss: 0.6351 - val_accuracy: 0.6483\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5858 - accuracy: 0.6787 - val_loss: 0.6287 - val_accuracy: 0.6608\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5783 - accuracy: 0.6842 - val_loss: 0.6300 - val_accuracy: 0.6508\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.6879 - val_loss: 0.6230 - val_accuracy: 0.6708\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.6950 - val_loss: 0.6288 - val_accuracy: 0.6558\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5664 - accuracy: 0.6971 - val_loss: 0.6171 - val_accuracy: 0.6617\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5605 - accuracy: 0.7006 - val_loss: 0.6135 - val_accuracy: 0.6692\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7048 - val_loss: 0.6149 - val_accuracy: 0.6758\n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5480 - accuracy: 0.7073 - val_loss: 0.6191 - val_accuracy: 0.6650\n",
      "Epoch 40/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5481 - accuracy: 0.7060 - val_loss: 0.6103 - val_accuracy: 0.6692\n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5394 - accuracy: 0.7117 - val_loss: 0.6207 - val_accuracy: 0.6675\n",
      "Epoch 42/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5381 - accuracy: 0.7181 - val_loss: 0.6055 - val_accuracy: 0.6817\n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7237 - val_loss: 0.5970 - val_accuracy: 0.6933\n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.7342 - val_loss: 0.5995 - val_accuracy: 0.6950\n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5164 - accuracy: 0.7317 - val_loss: 0.6039 - val_accuracy: 0.6883\n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5066 - accuracy: 0.7423 - val_loss: 0.6110 - val_accuracy: 0.6917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f304f6e1290>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10 = init_model()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model_10.fit(X_train_10, y_train_10, \n",
    "          epochs=500, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6066481994459834"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_test_y_10.sum()/len(apple_test_y_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.9457 - accuracy: 0.5305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9456890225410461, 0.5304709076881409]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.evaluate(apple_test_x_10, apple_test_y_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 5 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_train_x_5, apple_train_y_5 = build_arrays(train_df,input_cols=INPUT_COLS, target_col='5D_return_bin', time_window=30, stride=1)\n",
    "apple_test_x_5, apple_test_y_5 = build_arrays(test_df,input_cols=INPUT_COLS, target_col='5D_return_bin', time_window=30, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensei/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train_5 =  apple_train_x_5[[sample_indx], :][0]\n",
    "y_train_5 = apple_train_y_5[[sample_indx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.7010 - accuracy: 0.4948 - val_loss: 0.6927 - val_accuracy: 0.5242\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6950 - accuracy: 0.5081 - val_loss: 0.6922 - val_accuracy: 0.5208\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6930 - accuracy: 0.5244 - val_loss: 0.6913 - val_accuracy: 0.5267\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6917 - accuracy: 0.5329 - val_loss: 0.6913 - val_accuracy: 0.5283\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6899 - accuracy: 0.5369 - val_loss: 0.6914 - val_accuracy: 0.5167\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6907 - accuracy: 0.5290 - val_loss: 0.6905 - val_accuracy: 0.5258\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6901 - accuracy: 0.5342 - val_loss: 0.6901 - val_accuracy: 0.5367\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6900 - accuracy: 0.5450 - val_loss: 0.6898 - val_accuracy: 0.5250\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6882 - accuracy: 0.5452 - val_loss: 0.6888 - val_accuracy: 0.5325\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6849 - accuracy: 0.5510 - val_loss: 0.6895 - val_accuracy: 0.5208\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6870 - accuracy: 0.5446 - val_loss: 0.6882 - val_accuracy: 0.5267\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.5531 - val_loss: 0.6880 - val_accuracy: 0.5275\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6832 - accuracy: 0.5590 - val_loss: 0.6874 - val_accuracy: 0.5367\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6837 - accuracy: 0.5612 - val_loss: 0.6877 - val_accuracy: 0.5375\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6802 - accuracy: 0.5644 - val_loss: 0.6866 - val_accuracy: 0.5317\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6809 - accuracy: 0.5648 - val_loss: 0.6879 - val_accuracy: 0.5342\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6778 - accuracy: 0.5696 - val_loss: 0.6853 - val_accuracy: 0.5250\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6781 - accuracy: 0.5713 - val_loss: 0.6843 - val_accuracy: 0.5283\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6731 - accuracy: 0.5771 - val_loss: 0.6862 - val_accuracy: 0.5217\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6723 - accuracy: 0.5792 - val_loss: 0.6839 - val_accuracy: 0.5267\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6751 - accuracy: 0.5844 - val_loss: 0.6839 - val_accuracy: 0.5517\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6718 - accuracy: 0.5865 - val_loss: 0.6814 - val_accuracy: 0.5383\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6714 - accuracy: 0.5852 - val_loss: 0.6807 - val_accuracy: 0.5433\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6663 - accuracy: 0.5935 - val_loss: 0.6832 - val_accuracy: 0.5450\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6652 - accuracy: 0.6010 - val_loss: 0.6802 - val_accuracy: 0.5350\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6643 - accuracy: 0.5996 - val_loss: 0.6804 - val_accuracy: 0.5392\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6645 - accuracy: 0.5983 - val_loss: 0.6775 - val_accuracy: 0.5525\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6597 - accuracy: 0.5996 - val_loss: 0.6785 - val_accuracy: 0.5475\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6590 - accuracy: 0.6000 - val_loss: 0.6808 - val_accuracy: 0.5392\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6568 - accuracy: 0.6048 - val_loss: 0.6775 - val_accuracy: 0.5492\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6533 - accuracy: 0.6112 - val_loss: 0.6769 - val_accuracy: 0.5525\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6530 - accuracy: 0.6123 - val_loss: 0.6752 - val_accuracy: 0.5608\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6482 - accuracy: 0.6135 - val_loss: 0.6777 - val_accuracy: 0.5642\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6459 - accuracy: 0.6210 - val_loss: 0.6773 - val_accuracy: 0.5583\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6457 - accuracy: 0.6250 - val_loss: 0.6716 - val_accuracy: 0.5667\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.6187 - val_loss: 0.6718 - val_accuracy: 0.5792\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6414 - accuracy: 0.6221 - val_loss: 0.6728 - val_accuracy: 0.5717\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6390 - accuracy: 0.6248 - val_loss: 0.6682 - val_accuracy: 0.5717\n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6370 - accuracy: 0.6294 - val_loss: 0.6675 - val_accuracy: 0.5733\n",
      "Epoch 40/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6335 - accuracy: 0.6321 - val_loss: 0.6681 - val_accuracy: 0.5925\n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6346 - accuracy: 0.6404 - val_loss: 0.6650 - val_accuracy: 0.5800\n",
      "Epoch 42/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.6415 - val_loss: 0.6641 - val_accuracy: 0.5967\n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6261 - accuracy: 0.6494 - val_loss: 0.6626 - val_accuracy: 0.5858\n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.6513 - val_loss: 0.6683 - val_accuracy: 0.5817\n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6245 - accuracy: 0.6410 - val_loss: 0.6660 - val_accuracy: 0.5833\n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6161 - accuracy: 0.6517 - val_loss: 0.6605 - val_accuracy: 0.6067\n",
      "Epoch 47/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6139 - accuracy: 0.6554 - val_loss: 0.6635 - val_accuracy: 0.6133\n",
      "Epoch 48/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6117 - accuracy: 0.6558 - val_loss: 0.6589 - val_accuracy: 0.5975\n",
      "Epoch 49/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6070 - accuracy: 0.6610 - val_loss: 0.6602 - val_accuracy: 0.5967\n",
      "Epoch 50/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6073 - accuracy: 0.6633 - val_loss: 0.6609 - val_accuracy: 0.6092\n",
      "Epoch 51/500\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6013 - accuracy: 0.6654 - val_loss: 0.6540 - val_accuracy: 0.6242\n",
      "Epoch 52/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5990 - accuracy: 0.6673 - val_loss: 0.6498 - val_accuracy: 0.6067\n",
      "Epoch 53/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5977 - accuracy: 0.6769 - val_loss: 0.6482 - val_accuracy: 0.6117\n",
      "Epoch 54/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5941 - accuracy: 0.6773 - val_loss: 0.6488 - val_accuracy: 0.6158\n",
      "Epoch 55/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5909 - accuracy: 0.6748 - val_loss: 0.6487 - val_accuracy: 0.6142\n",
      "Epoch 56/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5872 - accuracy: 0.6794 - val_loss: 0.6428 - val_accuracy: 0.6408\n",
      "Epoch 57/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5813 - accuracy: 0.6879 - val_loss: 0.6410 - val_accuracy: 0.6233\n",
      "Epoch 58/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5828 - accuracy: 0.6827 - val_loss: 0.6485 - val_accuracy: 0.6150\n",
      "Epoch 59/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5780 - accuracy: 0.6854 - val_loss: 0.6455 - val_accuracy: 0.6275\n",
      "Epoch 60/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.6917 - val_loss: 0.6394 - val_accuracy: 0.6358\n",
      "Epoch 61/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5687 - accuracy: 0.6933 - val_loss: 0.6441 - val_accuracy: 0.6233\n",
      "Epoch 62/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5637 - accuracy: 0.6950 - val_loss: 0.6408 - val_accuracy: 0.6375\n",
      "Epoch 63/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5633 - accuracy: 0.6965 - val_loss: 0.6421 - val_accuracy: 0.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f305307a4d0>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = init_model()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model_5.fit(X_train_5, y_train_5, \n",
    "          epochs=500, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5858725761772853"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_test_y_5.sum()/len(apple_test_y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 1.5113 - accuracy: 0.4751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5112502574920654, 0.4750692546367645]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(apple_test_x_5, apple_test_y_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for 20 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import expand_dims\n",
    "X_train_cnn_20 = expand_dims(X_train_20, axis=-1)\n",
    "X_test_cnn_20 = expand_dims(apple_test_x_20, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_cnn():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(30, 15, 1)))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(60, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.4942 - val_loss: 0.6916 - val_accuracy: 0.5100\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6861 - val_accuracy: 0.5117\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5431 - val_loss: 0.6734 - val_accuracy: 0.5892\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6771 - accuracy: 0.5860 - val_loss: 0.6663 - val_accuracy: 0.6117\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6156 - val_loss: 0.6554 - val_accuracy: 0.6017\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6540 - val_loss: 0.6110 - val_accuracy: 0.6817\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6908 - val_loss: 0.5994 - val_accuracy: 0.6758\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7258 - val_loss: 0.5505 - val_accuracy: 0.7317\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7721 - val_loss: 0.5298 - val_accuracy: 0.7383\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7962 - val_loss: 0.5103 - val_accuracy: 0.7525\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8290 - val_loss: 0.4461 - val_accuracy: 0.8000\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8567 - val_loss: 0.4240 - val_accuracy: 0.8175\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8781 - val_loss: 0.4672 - val_accuracy: 0.8083\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9038 - val_loss: 0.4448 - val_accuracy: 0.8350\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9121 - val_loss: 0.3819 - val_accuracy: 0.8542\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9269 - val_loss: 0.4257 - val_accuracy: 0.8500\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9296 - val_loss: 0.4523 - val_accuracy: 0.8533\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.9425 - val_loss: 0.4284 - val_accuracy: 0.8600\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9450 - val_loss: 0.4754 - val_accuracy: 0.8467\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9556 - val_loss: 0.3992 - val_accuracy: 0.8808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f304ec78390>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_20 = initialize_model_cnn()\n",
    "\n",
    "model_cnn_20.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_cnn_20.fit(X_train_cnn_20, y_train_20, \n",
    "          epochs=500, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 1.7293 - accuracy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.729311466217041, 0.4819944500923157]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_20.evaluate(X_test_cnn_20, apple_test_y_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for 10 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn_10 = expand_dims(X_train_10, axis=-1)\n",
    "X_test_cnn_10 = expand_dims(apple_test_x_10, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.5133 - val_loss: 0.6929 - val_accuracy: 0.5050\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5058 - val_loss: 0.6926 - val_accuracy: 0.5083\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5175 - val_loss: 0.6902 - val_accuracy: 0.5375\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5269 - val_loss: 0.6907 - val_accuracy: 0.5458\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5371 - val_loss: 0.6917 - val_accuracy: 0.5092\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5512 - val_loss: 0.6819 - val_accuracy: 0.5592\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5665 - val_loss: 0.6833 - val_accuracy: 0.5633\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5950 - val_loss: 0.6648 - val_accuracy: 0.5925\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6338 - val_loss: 0.6487 - val_accuracy: 0.6150\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6196 - accuracy: 0.6544 - val_loss: 0.6329 - val_accuracy: 0.6275\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6935 - val_loss: 0.6017 - val_accuracy: 0.6758\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7215 - val_loss: 0.6048 - val_accuracy: 0.6842\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7550 - val_loss: 0.6138 - val_accuracy: 0.6925\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7883 - val_loss: 0.5821 - val_accuracy: 0.6958\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8260 - val_loss: 0.5356 - val_accuracy: 0.7400\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8367 - val_loss: 0.5207 - val_accuracy: 0.7683\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8606 - val_loss: 0.5162 - val_accuracy: 0.7833\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8815 - val_loss: 0.5453 - val_accuracy: 0.7850\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8971 - val_loss: 0.5826 - val_accuracy: 0.7850\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9052 - val_loss: 0.5570 - val_accuracy: 0.7933\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9215 - val_loss: 0.6206 - val_accuracy: 0.7933\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9277 - val_loss: 0.6818 - val_accuracy: 0.7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f304e28d7d0>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_10 = initialize_model_cnn()\n",
    "\n",
    "model_cnn_10.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_cnn_10.fit(X_train_cnn_10, y_train_10, \n",
    "          epochs=500, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 2.4122 - accuracy: 0.4114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4122228622436523, 0.4113573431968689]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_10.evaluate(X_test_cnn_10, apple_test_y_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for 5 days future returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn_5 = expand_dims(X_train_5, axis=-1)\n",
    "X_test_cnn_5 = expand_dims(apple_test_x_5, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.5079 - val_loss: 0.6929 - val_accuracy: 0.5067\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5106 - val_loss: 0.6935 - val_accuracy: 0.5092\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5108 - val_loss: 0.6931 - val_accuracy: 0.5175\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5250 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5377 - val_loss: 0.6939 - val_accuracy: 0.5167\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5356 - val_loss: 0.6923 - val_accuracy: 0.5058\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5452 - val_loss: 0.6908 - val_accuracy: 0.5233\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5550 - val_loss: 0.6905 - val_accuracy: 0.5375\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5573 - val_loss: 0.6858 - val_accuracy: 0.5375\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6781 - accuracy: 0.5619 - val_loss: 0.6855 - val_accuracy: 0.5433\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5771 - val_loss: 0.6794 - val_accuracy: 0.5625\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6015 - val_loss: 0.6749 - val_accuracy: 0.5700\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6146 - val_loss: 0.6920 - val_accuracy: 0.5658\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6338 - val_loss: 0.6618 - val_accuracy: 0.5967\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.6535 - val_loss: 0.6774 - val_accuracy: 0.5908\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6929 - val_loss: 0.6798 - val_accuracy: 0.6058\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7131 - val_loss: 0.6379 - val_accuracy: 0.6542\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7408 - val_loss: 0.6820 - val_accuracy: 0.6425\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7706 - val_loss: 0.6835 - val_accuracy: 0.6583\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7875 - val_loss: 0.6748 - val_accuracy: 0.6558\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8223 - val_loss: 0.7050 - val_accuracy: 0.6725\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8429 - val_loss: 0.7737 - val_accuracy: 0.6567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f304e0d9d50>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_5 = initialize_model_cnn()\n",
    "\n",
    "model_cnn_5.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_cnn_5.fit(X_train_cnn_5, y_train_5, \n",
    "          epochs=500, \n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 2.4927 - accuracy: 0.4294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4926819801330566, 0.4293628931045532]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_10.evaluate(X_test_cnn_5, apple_test_y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
